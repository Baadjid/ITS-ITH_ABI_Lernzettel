<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KI Lernzettel - Abitur Vorbereitung</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
    :root {
        --primary-color: #2563eb;
        --secondary-color: #1e40af;
        --accent-color: #3b82f6;
        --bg-color: #f8fafc;
        --card-bg: #ffffff;
        --text-primary: #1e293b;
        --text-secondary: #475569;
        --border-color: #e2e8f0;
        --success-color: #10b981;
        --warning-color: #f59e0b;
        --danger-color: #ef4444;
    }

    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        line-height: 1.7;
        color: var(--text-primary);
        background: var(--bg-color);
        padding-top: 80px;
    }

    /* Header & Navigation */
    header {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        color: white;
        padding: 1.5rem 0;
        top: 0;
        width: 100%;
        z-index: 1000;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }

    header h1 {
        text-align: center;
        font-size: 2rem;
        margin-bottom: 0.5rem;
    }

    nav {
        background: var(--card-bg);
        padding: 1rem 0;
        position: sticky;
        top: 0px;
        z-index: 999;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    nav ul {
        display: flex;
        justify-content: center;
        flex-wrap: wrap;
        list-style: none;
        max-width: 1200px;
        margin: 0 auto;
        padding: 0 2rem;
    }

    nav li {
        margin: 0.5rem;
    }

    nav a {
        color: var(--text-primary);
        text-decoration: none;
        padding: 0.5rem 1rem;
        border-radius: 6px;
        transition: all 0.3s ease;
        font-weight: 500;
    }

    nav a:hover {
        background: var(--primary-color);
        color: white;
    }

    /* Container */
    .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
    }

    /* Sections */
    section {
        background: var(--card-bg);
        margin: 2rem 0;
        padding: 2.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
    }

    section h2 {
        color: var(--primary-color);
        font-size: 2rem;
        margin-bottom: 1.5rem;
        padding-bottom: 0.75rem;
        border-bottom: 3px solid var(--primary-color);
    }

    section h3 {
        color: var(--secondary-color);
        font-size: 1.5rem;
        margin: 2rem 0 1rem;
    }

    section h4 {
        color: var(--text-primary);
        font-size: 1.2rem;
        margin: 1.5rem 0 0.75rem;
        font-weight: 600;
    }

    /* Cards */
    .card {
        background: var(--bg-color);
        padding: 1.5rem;
        margin: 1.5rem 0;
        border-radius: 8px;
        border-left: 4px solid var(--primary-color);
    }

    .card-success {
        border-left-color: var(--success-color);
    }

    .card-warning {
        border-left-color: var(--warning-color);
    }

    .card-danger {
        border-left-color: var(--danger-color);
    }

    /* Formula Box */
    .formula {
        background: #f1f5f9;
        padding: 1.5rem;
        margin: 1rem 0;
        border-radius: 8px;
        font-family: 'Courier New', monospace;
        font-size: 1.1rem;
        overflow-x: auto;
        border: 2px solid var(--border-color);
    }

    /* Code Block */
    pre {
        background: #1e293b;
        color: #e2e8f0;
        padding: 1.5rem;
        border-radius: 8px;
        overflow-x: auto;
        margin: 1rem 0;
        font-size: 0.9rem;
        line-height: 1.6;
    }

    /* Lists */
    ul, ol {
        margin: 1rem 0 1rem 2rem;
    }

    li {
        margin: 0.5rem 0;
    }

    /* Tables */
    table {
        width: 100%;
        border-collapse: collapse;
        margin: 1.5rem 0;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    th, td {
        padding: 1rem;
        text-align: left;
        border: 1px solid var(--border-color);
    }

    th {
        background: var(--primary-color);
        color: white;
        font-weight: 600;
    }

    tr:nth-child(even) {
        background: var(--bg-color);
    }

    /* Highlight Box */
    .highlight {
        background: linear-gradient(135deg, #dbeafe, #bfdbfe);
        padding: 1.5rem;
        border-radius: 8px;
        margin: 1.5rem 0;
        border-left: 4px solid var(--primary-color);
    }

    .highlight strong {
        color: var(--primary-color);
    }

    /* Important Note */
    .wichtig {
        background: #fef3c7;
        padding: 1rem 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        border-left: 4px solid var(--warning-color);
    }

    .wichtig::before {
        content: "‚ö†Ô∏è Wichtig: ";
        font-weight: bold;
        color: var(--warning-color);
    }

    /* Example Box */
    .beispiel {
        background: #d1fae5;
        padding: 1.5rem;
        border-radius: 8px;
        margin: 1.5rem 0;
        border-left: 4px solid var(--success-color);
    }

    .beispiel h4 {
        color: var(--success-color);
        margin-top: 0;
    }

    /* Two Column Layout */
    .two-column {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 2rem;
        margin: 1.5rem 0;
    }

    /* Responsive */
    @media (max-width: 768px) {
    /* Tabellen scrollbar machen */
    table {
        display: block;
        overflow-x: auto;
        -webkit-overflow-scrolling: touch;
        font-size: 0.85rem;
    }
    
    th, td {
        padding: 0.75rem 0.5rem;
        min-width: 100px;
    }
    
    /* Formeln anpassen */
    .formula {
        font-size: 0.85rem;
        padding: 1rem;
    }
    
    /* Pre/Code kleiner */
    pre {
        font-size: 0.75rem;
        padding: 1rem;
    }
    
    /* Breadcrumb anpassen */
    .breadcrumb {
        font-size: 0.85rem;
        padding: 0.75rem;
    }
    
    /* Cards mit weniger Padding */
    .card, .card-success, .card-warning, .card-danger {
        padding: 1rem;
    }
    
    .beispiel, .wichtig, .highlight {
        padding: 1rem;
    }
}

    /* Print Styles */
    @media print {
        body {
            padding-top: 0;
        }

        header, nav {
            position: static;
        }

        section {
            page-break-inside: avoid;
        }
    }

    /* Smooth Scroll */
    html {
        scroll-behavior: smooth;
    }

    /* Strong emphasis */
    strong {
        color: var(--primary-color);
        font-weight: 600;
    }

    p {
        margin: 1rem 0;
    }

        /* F√ºr sehr kleine Handys */
@media (max-width: 400px) {
    body {
        padding-top: 50px;
    }
    
    header h1 {
        font-size: 1.25rem;
    }
    
    header p {
        font-size: 0.85rem;
    }
    
    .container {
        padding: 0.5rem;
    }
    
    section {
        padding: 1rem;
        margin: 1rem 0;
    }
    
    section h2 {
        font-size: 1.3rem;
    }
    
    section h3 {
        font-size: 1.15rem;
    }
    
    nav a {
        padding: 0.4rem 0.8rem;
        font-size: 0.85rem;
    }
}
</style>
</head>
<body>
    <header>
        <h1>ü§ñ K√ºnstliche Intelligenz - Abitur Lernzettel</h1>
        <p style="text-align: center; opacity: 0.9;">Umfassende Vorbereitung f√ºr das Informatik-Abitur</p>
    </header>
<nav>
    <ul>
        <li><a href="#ueberblick">√úberblick</a></li>
        <li><a href="#knn">k-NN Verfahren</a></li>
        <li><a href="#kmeans">K-Means</a></li>
        <li><a href="#minmax">Min-Max</a></li>
        <li><a href="#implementierungen">Code-Beispiele</a></li>
        <li><a href="#pruefungstipps-code">Pr√ºfungstipps</a></li>
        <li><a href="#zusammenfassung">Zusammenfassung</a></li>
    </ul>
</nav>
<div class="container">
    <div class="breadcrumb">
         üè† <a href="index.html">Abitur 2026 Informatik TG</a> ‚Üí 
        <a >√úberblick √ºber K√ºnstliche Intelligenz</a> 
    </div>
    <!-- √úberblick Section -->
    <section id="ueberblick">
        <h2>√úberblick √ºber K√ºnstliche Intelligenz</h2>
        
        <div class="highlight">
            <strong>K√ºnstliche Intelligenz (KI)</strong> bezeichnet Systeme, die menschen√§hnliche Intelligenzleistungen erbringen. Im Abitur werden verschiedene KI-Ans√§tze unterschieden: wissensbasierte Systeme und maschinelles Lernen. 
        </div>
        
        <div class="highlight">
            üëæ <a href="https://www.geeksforgeeks.org/machine-learning/machine-learning/">Machine Learning Source</a> 
        </div>

        <h3>Definitionen und Grundkonzepte</h3>
        <div class="two-column">
            <div class="card">
                <h4>Starke KI (Strong AI)</h4>
                <p>Systeme mit echtem Bewusstsein und Verst√§ndnis, die menschliche Intelligenz vollst√§ndig nachbilden k√∂nnen.</p>
            </div>
            <div class="card">
                <h4>Schwache KI (Weak AI)</h4>
                <p>Systeme f√ºr spezifische Aufgaben ohne echtes Verst√§ndnis. Beispiele: Sprachassistenten, Bilderkennung, Empfehlungssysteme.</p>
            </div>
        </div>

        <h3>Kategorien von KI-Ans√§tzen</h3>
        
        <h4>1. Wissensbasierte Ans√§tze</h4>
        <div class="card card-success">
            <p><strong>Definition:</strong> Systeme, bei denen Wissen explizit und nachvollziehbar gespeichert, erzeugt, genutzt oder abgefragt werden kann.</p>
            
            <p><strong>Komponenten:</strong></p>
            <ul>
                <li><strong>Suchalgorithmen</strong> (z.B. A*-Algorithmus) </li>
                <li><strong>Expertensysteme</strong> mit von Experten bereitgestellten Regeln </li>
                <li><strong>Entscheidungsbaumlernen</strong> </li>
            </ul>

            <p><strong>Vorteile:</strong></p>
            <ul>
                <li>‚úÖ Schlussfolgerungen sind nachvollziehbar (<em>Folgerichtigkeit</em>) </li>
                <li>‚úÖ Transparente Entscheidungsfindung</li>
            </ul>

            <p><strong>Nachteile:</strong></p>
            <ul>
                <li>‚ùå Nicht vollst√§ndig: Kann einfache Aufgaben wie Bild-Unterscheidung nicht l√∂sen </li>
                <li>‚ùå Wissen muss explizit formulierbar sein</li>
            </ul>
        </div>

        <h4>2. Maschinelles Lernen</h4>
        <div class="card card-success">
            <p><strong>Definition:</strong> Ein System wird f√ºr seine Aufgabe "trainiert" anstatt explizit programmiert. </p>
            
            <p><strong>Ans√§tze:</strong></p>
            <ul>
                <li><strong>√úberwachtes Lernen</strong> (Supervised Learning): Training mit gelabelten Daten</li>
                <li><strong>Un√ºberwachtes Lernen</strong> (Unsupervised Learning): Muster in ungelabelten Daten finden</li>
                <li><strong>Verst√§rkendes Lernen</strong> (Reinforcement Learning): Lernen durch Belohnung/Bestrafung</li>
            </ul>
        </div>

        <h3>Turing-Test</h3>
        <p>Der nach Alan Turing benannte Test stellt die Frage: <em>"Wie k√∂nnen wir feststellen, ob eine Maschine intelligent ist?"</em></p>
        <p>Ein Mensch kommuniziert mit einer Maschine und einem anderen Menschen, ohne zu wissen, wer wer ist. Kann der Mensch nicht unterscheiden, welcher Gespr√§chspartner die Maschine ist, gilt der Test als bestanden.</p>

        <h3>Wichtige Begriffe f√ºr das Abitur</h3>
        <table>
            <tr>
                <th>Begriff</th>
                <th>Erkl√§rung</th>
            </tr>
            <tr>
                <td><strong>Gelabelte Daten</strong></td>
                <td>Daten, die bereits einer Klasse zugeordnet wurden </td>
            </tr>
            <tr>
                <td><strong>Trainingsdaten</strong></td>
                <td>Gelabelte Daten zum "Trainieren" des Algorithmus </td>
            </tr>
            <tr>
                <td><strong>Testdaten</strong></td>
                <td>Gelabelte Daten zur Evaluation der Algorithmusqualit√§t </td>
            </tr>
            <tr>
                <td><strong>Overfitting</strong></td>
                <td>√úberanpassung an Trainingsdaten, schlechte Generalisierung</td>
            </tr>
            <tr>
                <td><strong>Underfitting</strong></td>
                <td>Zu einfaches Modell, erfasst Muster nicht ausreichend</td>
            </tr>
        </table>
    </section>

    <!-- Gini-Index & Decision Trees Section -->
<section id="gini">
    <h2>Gini-Index & Entscheidungsb√§ume (Decision Trees)</h2>

    <div class="highlight">
        <strong>Der Gini-Index</strong> ist ein Ma√ü f√ºr die Unreinheit (Impurity) in einem Datensatz. Er wird verwendet, um zu entscheiden, welches Feature am besten f√ºr die Aufteilung eines Entscheidungsbaums geeignet ist.
    </div>

    <h3>Grundkonzept</h3>
    <p>Decision Trees (Entscheidungsb√§ume) sind √ºberwachte Lernverfahren zur Klassifikation und Regression. Der Baum wird durch rekursive Aufteilung der Daten nach Features erstellt, wobei das Ziel ist, m√∂glichst "reine" Bl√§tter zu erzeugen.</p>

    <div class="card">
        <p><strong>Charakteristika:</strong></p>
        <ul>
            <li>üîπ <strong>√úberwachtes Lernen</strong>: Ben√∂tigt gelabelte Trainingsdaten</li>
            <li>üîπ <strong>Wissensbasierter Ansatz</strong>: Entscheidungsregeln sind nachvollziehbar</li>
            <li>üîπ Funktioniert f√ºr kategorische und numerische Features</li>
            <li>üîπ Baumartige Struktur mit Entscheidungsknoten und Bl√§ttern</li>
        </ul>
    </div>

    <h3>Gini-Index Formel</h3>
    <div class="formula">
Gini(D) = 1 - Œ£(p<sub>i</sub>)¬≤

wobei:
- D = Datensatz
- p<sub>i</sub> = Anteil der Klasse i im Datensatz
- Summe √ºber alle Klassen
    </div>

    <div class="card card-success">
        <p><strong>Interpretation:</strong></p>
        <ul>
            <li><strong>Gini = 0:</strong> Perfekte Reinheit (alle Datenpunkte geh√∂ren zur selben Klasse)</li>
            <li><strong>Gini = 0.5:</strong> Maximale Unreinheit bei 2 Klassen (50/50 Verteilung)</li>
            <li><strong>Gini klein:</strong> Datensatz ist homogen, gute Aufteilung</li>
            <li><strong>Gini gro√ü:</strong> Datensatz ist heterogen, schlechte Aufteilung</li>
        </ul>
    </div>

    <h3>Gini-Index f√ºr Feature-Aufteilung</h3>
    <p>Um zu entscheiden, welches Feature f√ºr die Aufteilung verwendet wird, berechnet man den <strong>gewichteten Gini-Index</strong> nach der Aufteilung:</p>

    <div class="formula">
Gini<sub>split</sub>(Feature) = Œ£ (n<sub>i</sub>/n) √ó Gini(D<sub>i</sub>)

wobei:
- n<sub>i</sub> = Anzahl Datenpunkte in Teilmenge i
- n = Gesamtanzahl Datenpunkte
- D<sub>i</sub> = Teilmenge nach Aufteilung
    </div>

    <div class="wichtig">
        Das Feature mit dem <strong>niedrigsten gewichteten Gini-Index</strong> wird f√ºr die Aufteilung gew√§hlt!
    </div>

    <h3>Beispielaufgabe: Gini-Berechnung</h3>
    <div class="beispiel">
        <h4>Gegeben: Dataset mit Feature "Money" und Klassen {Cinema, Tennis, Shopping, Stay In}</h4>
        
        <table>
            <tr>
                <th>Weekend</th>
                <th>Weather</th>
                <th>Money</th>
                <th>Decision</th>
            </tr>
            <tr>
                <td>W1</td>
                <td>Sunny</td>
                <td>Rich</td>
                <td>Cinema</td>
            </tr>
            <tr>
                <td>W2</td>
                <td>Sunny</td>
                <td>Rich</td>
                <td>Tennis</td>
            </tr>
            <tr>
                <td>W3</td>
                <td>Windy</td>
                <td>Rich</td>
                <td>Cinema</td>
            </tr>
            <tr>
                <td>W4</td>
                <td>Rainy</td>
                <td>Poor</td>
                <td>Cinema</td>
            </tr>
            <tr>
                <td>W5</td>
                <td>Rainy</td>
                <td>Rich</td>
                <td>Stay In</td>
            </tr>
        </table>

        <p><strong>Aufgabe:</strong> Berechne Gini(Money)</p>

        <p><strong>Schritt 1: Aufteilung nach Money</strong></p>
        <ul>
            <li><strong>Rich:</strong> 4 Datenpunkte ‚Üí {Cinema: 2, Tennis: 1, Stay In: 1}</li>
            <li><strong>Poor:</strong> 1 Datenpunkt ‚Üí {Cinema: 1}</li>
        </ul>

        <p><strong>Schritt 2: Gini f√ºr "Rich"</strong></p>
        <pre>
Gini(Rich) = 1 - [(2/4)¬≤ + (1/4)¬≤ + (1/4)¬≤ + (0/4)¬≤]
           = 1 - [0.25 + 0.0625 + 0.0625 + 0]
           = 1 - 0.375
           = 0.625
        </pre>

        <p><strong>Schritt 3: Gini f√ºr "Poor"</strong></p>
        <pre>
Gini(Poor) = 1 - [(1/1)¬≤]
           = 1 - 1
           = 0  (perfekt rein!)
        </pre>

        <p><strong>Schritt 4: Gewichteter Gini f√ºr Money</strong></p>
        <pre>
Gini(Money) = (4/5) √ó 0.625 + (1/5) √ó 0
            = 0.8 √ó 0.625 + 0.2 √ó 0
            = 0.5
        </pre>

        <p><strong>Ergebnis:</strong> Gini(Money) = 0.5</p>
    </div>

    <h3>Algorithmus: Entscheidungsbaum erstellen</h3>
    <div class="card card-success">
        <ol>
            <li><strong>Start:</strong> Wurzelknoten mit allen Trainingsdaten</li>
            <li><strong>Feature-Auswahl:</strong> Berechne Gini-Index f√ºr jedes Feature</li>
            <li><strong>Split:</strong> W√§hle Feature mit niedrigstem Gini und teile Daten auf</li>
            <li><strong>Rekursion:</strong> Wiederhole f√ºr jeden Teilbaum</li>
            <li><strong>Stopp-Kriterien:</strong>
                <ul>
                    <li>Maximale Baumtiefe erreicht</li>
                    <li>Minimale Anzahl Datenpunkte pro Knoten unterschritten</li>
                    <li>Gini = 0 (perfekt rein)</li>
                    <li>Keine Features mehr verf√ºgbar</li>
                </ul>
            </li>
        </ol>
    </div>

    <h3>Entropy vs. Gini-Index</h3>
    <table>
        <tr>
            <th>Kriterium</th>
            <th>Gini-Index</th>
            <th>Entropy (Information Gain)</th>
        </tr>
        <tr>
            <td><strong>Formel</strong></td>
            <td>Gini = 1 - Œ£p<sub>i</sub>¬≤</td>
            <td>Entropy = -Œ£p<sub>i</sub> √ó log<sub>2</sub>(p<sub>i</sub>)</td>
        </tr>
        <tr>
            <td><strong>Wertebereich</strong></td>
            <td>[0, 0.5] bei 2 Klassen</td>
            <td>[0, 1] bei 2 Klassen</td>
        </tr>
        <tr>
            <td><strong>Berechnung</strong></td>
            <td>Schneller (keine Logarithmen)</td>
            <td>Langsamer (Logarithmen)</td>
        </tr>
        <tr>
            <td><strong>Verwendung</strong></td>
            <td>CART-Algorithmus</td>
            <td>ID3, C4.5 Algorithmen</td>
        </tr>
        <tr>
            <td><strong>Ergebnis</strong></td>
            <td>Meist √§hnlich zu Entropy</td>
            <td>Meist √§hnlich zu Gini</td>
        </tr>
    </table>

    <h3>Vorteile und Nachteile von Decision Trees</h3>
    <div class="two-column">
        <div class="card card-success">
            <h4>Vorteile ‚úÖ</h4>
            <ul>
                <li>Leicht verst√§ndlich und interpretierbar</li>
                <li>Visuell darstellbar</li>
                <li>Ben√∂tigt wenig Datenaufbereitung</li>
                <li>Funktioniert mit numerischen und kategorischen Daten</li>
                <li>Keine Annahmen √ºber Datenverteilung</li>
                <li>Schnell bei Vorhersagen</li>
            </ul>
        </div>
        <div class="card card-danger">
            <h4>Nachteile ‚ùå</h4>
            <ul>
                <li>Neigung zu Overfitting</li>
                <li>Instabil (kleine √Ñnderungen ‚Üí anderer Baum)</li>
                <li>Bias zu Features mit vielen Werten</li>
                <li>Kann keine XOR-Probleme l√∂sen</li>
                <li>Greedy-Algorithmus (nicht global optimal)</li>
            </ul>
        </div>
    </div>

    <h3>Pruning (Beschneidung)</h3>
    <p>Um Overfitting zu vermeiden, werden Entscheidungsb√§ume nach dem Training "beschnitten":</p>
    
    <div class="card">
        <p><strong>Pre-Pruning (fr√ºhes Stoppen):</strong></p>
        <ul>
            <li>Maximale Baumtiefe festlegen</li>
            <li>Minimale Anzahl Samples pro Knoten</li>
            <li>Minimaler Gini-Verbesserung f√ºr Split</li>
        </ul>

        <p><strong>Post-Pruning (nachtr√§gliches Beschneiden):</strong></p>
        <ul>
            <li>Erst vollst√§ndigen Baum erstellen</li>
            <li>Dann Zweige entfernen, die Generalisierung verbessern</li>
            <li>Cost Complexity Pruning (Œ±-Parameter)</li>
        </ul>
    </div>

    <h3>Random Forest - Ensemble von Decision Trees</h3>
    <div class="highlight">
        <p><strong>Random Forest</strong> kombiniert viele Entscheidungsb√§ume, um Overfitting zu reduzieren und Genauigkeit zu verbessern.</p>
        <p><strong>Prinzip:</strong> Trainiere viele B√§ume mit zuf√§lligen Teilmengen der Daten und Features ‚Üí Mehrheitsentscheidung</p>
    </div>

    <h3>Anwendungen</h3>
    <ul>
        <li><strong>Medizin:</strong> Diagnose-Entscheidungen (z.B. Krankheitserkennung)</li>
        <li><strong>Finanzen:</strong> Kreditw√ºrdigkeit bewerten</li>
        <li><strong>Marketing:</strong> Kundensegmentierung</li>
        <li><strong>Qualit√§tskontrolle:</strong> Fehlerklassifikation</li>
        <li><strong>Empfehlungssysteme:</strong> Produkt-Empfehlungen</li>
    </ul>

    <div class="wichtig">
        <strong>Pr√ºfungsrelevant:</strong>
        <ul>
            <li>Gini-Index f√ºr Features berechnen k√∂nnen</li>
            <li>Verstehen, warum niedrigerer Gini besser ist</li>
            <li>Gewichteten Gini nach Split berechnen</li>
            <li>Feature mit bestem Split ausw√§hlen k√∂nnen</li>
            <li>Overfitting-Problem und Pruning erkl√§ren</li>
        </ul>
    </div>
</section>

<!-- Dijkstra-Algorithmus Section -->
<section id="dijkstra">
    <h2>Dijkstra-Algorithmus (K√ºrzeste Wege)</h2>

    <div class="highlight">
        <strong>Der Dijkstra-Algorithmus</strong> wurde 1959 von Edsger W. Dijkstra entwickelt und findet die k√ºrzesten Wege von einem Startknoten zu allen anderen Knoten in einem gewichteten Graphen mit nicht-negativen Kantengewichten.
    </div>

    <h3>Grundkonzept</h3>
    <p>Dijkstra geh√∂rt zur Klasse der <strong>Greedy-Algorithmen</strong> (gierige Algorithmen): In jedem Schritt wird die lokal beste Entscheidung getroffen ‚Äì der Knoten mit den aktuell geringsten bekannten Kosten.</p>

    <div class="card">
        <p><strong>Voraussetzungen:</strong></p>
        <ul>
            <li>üîπ Gewichteter, gerichteter oder ungerichteter Graph</li>
            <li>üîπ <strong>Alle Kantengewichte m√ºssen ‚â• 0 sein</strong> (keine negativen Gewichte!)</li>
            <li>üîπ Zusammenh√§ngender Graph (alle Knoten erreichbar)</li>
        </ul>

        <p><strong>Ziel:</strong></p>
        <ul>
            <li>Finde k√ºrzesten Weg vom Startknoten zu allen anderen Knoten</li>
            <li>Berechne minimale Distanzen (Kosten)</li>
        </ul>
    </div>

    <h3>Algorithmus-Schritte</h3>
    <div class="card card-success">
        <ol>
            <li><strong>Initialisierung:</strong>
                <ul>
                    <li>Startknoten erh√§lt Distanz 0</li>
                    <li>Alle anderen Knoten: Distanz = ‚àû</li>
                    <li>Alle Knoten als "unbesucht" markieren</li>
                </ul>
            </li>
            <li><strong>Knotenwahl:</strong> W√§hle unbesuchten Knoten mit kleinster Distanz</li>
            <li><strong>Relaxation (Entspannung):</strong>
                <ul>
                    <li>F√ºr jeden Nachbarn des aktuellen Knotens:</li>
                    <li>Berechne: neue_distanz = distanz[aktuell] + kantengewicht</li>
                    <li>Wenn neue_distanz < distanz[nachbar]:</li>
                    <li>‚Üí Aktualisiere distanz[nachbar]</li>
                    <li>‚Üí Speichere Vorg√§nger f√ºr Wegrekonstruktion</li>
                </ul>
            </li>
            <li><strong>Markierung:</strong> Markiere aktuellen Knoten als "besucht"</li>
            <li><strong>Wiederholung:</strong> Gehe zu Schritt 2, bis alle Knoten besucht sind</li>
        </ol>
    </div>

    <h3>Pseudocode</h3>
    <pre>
FUNKTION dijkstra(Graph G, Knoten start):
    // Initialisierung
    F√úR JEDEN Knoten v IN G:
        distanz[v] = ‚àû
        vorg√§nger[v] = null
        unbesucht.add(v)
    ENDE F√úR
    
    distanz[start] = 0
    
    // Hauptschleife
    SOLANGE unbesucht nicht leer:
        // W√§hle Knoten mit kleinster Distanz
        u = knoten_mit_minimaler_distanz(unbesucht)
        unbesucht.remove(u)
        
        // Relaxation f√ºr alle Nachbarn
        F√úR JEDEN Nachbarn v von u:
            alternative = distanz[u] + gewicht(u, v)
            
            WENN alternative < distanz[v]:
                distanz[v] = alternative
                vorg√§nger[v] = u
            ENDE WENN
        ENDE F√úR
    ENDE SOLANGE
    
    RETURN distanz, vorg√§nger
ENDE FUNKTION
    </pre>

    <h3>Beispiel: Dijkstra Schritt-f√ºr-Schritt</h3>
    <div class="beispiel">
        <h4>Gegeben: Graph mit Knoten A, B, C, D, E</h4>
        
        <p><strong>Kanten und Gewichte:</strong></p>
        <ul>
            <li>A ‚Üí B: 100</li>
            <li>A ‚Üí D: 50</li>
            <li>B ‚Üí C: 100</li>
            <li>B ‚Üí E: 250</li>
            <li>C ‚Üí E: 50</li>
            <li>D ‚Üí B: 100</li>
            <li>D ‚Üí E: 250</li>
        </ul>

        <p><strong>Iteration 0 (Initialisierung):</strong></p>
        <table>
            <tr>
                <th>Knoten</th>
                <th>Distanz</th>
                <th>Vorg√§nger</th>
                <th>Besucht</th>
            </tr>
            <tr>
                <td>A (Start)</td>
                <td>0</td>
                <td>-</td>
                <td>‚ùå</td>
            </tr>
            <tr>
                <td>B</td>
                <td>‚àû</td>
                <td>-</td>
                <td>‚ùå</td>
            </tr>
            <tr>
                <td>C</td>
                <td>‚àû</td>
                <td>-</td>
                <td>‚ùå</td>
            </tr>
            <tr>
                <td>D</td>
                <td>‚àû</td>
                <td>-</td>
                <td>‚ùå</td>
            </tr>
            <tr>
                <td>E</td>
                <td>‚àû</td>
                <td>-</td>
                <td>‚ùå</td>
            </tr>
        </table>

        <p><strong>Iteration 1: W√§hle A (Distanz = 0)</strong></p>
        <ul>
            <li>Nachbar B: 0 + 100 = 100 < ‚àû ‚Üí distanz[B] = 100, vorg√§nger[B] = A</li>
            <li>Nachbar D: 0 + 50 = 50 < ‚àû ‚Üí distanz[D] = 50, vorg√§nger[D] = A</li>
            <li>A als besucht markieren ‚úÖ</li>
        </ul>

        <p><strong>Iteration 2: W√§hle D (Distanz = 50)</strong></p>
        <ul>
            <li>Nachbar B: 50 + 100 = 150 > 100 ‚Üí keine √Ñnderung</li>
            <li>Nachbar E: 50 + 250 = 300 < ‚àû ‚Üí distanz[E] = 300, vorg√§nger[E] = D</li>
            <li>D als besucht markieren ‚úÖ</li>
        </ul>

        <p><strong>Iteration 3: W√§hle B (Distanz = 100)</strong></p>
        <ul>
            <li>Nachbar C: 100 + 100 = 200 < ‚àû ‚Üí distanz[C] = 200, vorg√§nger[C] = B</li>
            <li>Nachbar E: 100 + 250 = 350 > 300 ‚Üí keine √Ñnderung</li>
            <li>B als besucht markieren ‚úÖ</li>
        </ul>

        <p><strong>Iteration 4: W√§hle C (Distanz = 200)</strong></p>
        <ul>
            <li>Nachbar E: 200 + 50 = 250 < 300 ‚Üí distanz[E] = 250, vorg√§nger[E] = C</li>
            <li>C als besucht markieren ‚úÖ</li>
        </ul>

        <p><strong>Iteration 5: W√§hle E (Distanz = 250)</strong></p>
        <ul>
            <li>Keine unbesuchten Nachbarn</li>
            <li>E als besucht markieren ‚úÖ</li>
        </ul>

        <p><strong>Endergebnis:</strong></p>
        <table>
            <tr>
                <th>Zielknoten</th>
                <th>K√ºrzeste Distanz</th>
                <th>K√ºrzester Weg</th>
            </tr>
            <tr>
                <td>A</td>
                <td>0</td>
                <td>A</td>
            </tr>
            <tr>
                <td>B</td>
                <td>100</td>
                <td>A ‚Üí B</td>
            </tr>
            <tr>
                <td>C</td>
                <td>200</td>
                <td>A ‚Üí B ‚Üí C</td>
            </tr>
            <tr>
                <td>D</td>
                <td>50</td>
                <td>A ‚Üí D</td>
            </tr>
            <tr>
                <td>E</td>
                <td>250</td>
                <td>A ‚Üí B ‚Üí C ‚Üí E</td>
            </tr>
        </table>
    </div>

    <h3>Wegrekonstruktion</h3>
    <p>Um den tats√§chlichen Pfad zu erhalten, folgt man den Vorg√§ngern r√ºckw√§rts:</p>

    <div class="formula">
FUNKTION rekonstruiere_weg(vorg√§nger, start, ziel):
    weg = []
    aktuell = ziel
    
    SOLANGE aktuell ‚â† null:
        weg.add(aktuell)
        aktuell = vorg√§nger[aktuell]
    ENDE SOLANGE
    
    weg.reverse()  // Umdrehen f√ºr korrekte Reihenfolge
    RETURN weg
ENDE FUNKTION
    </div>

    <h3>Zeitkomplexit√§t</h3>
    <table>
        <tr>
            <th>Implementierung</th>
            <th>Zeitkomplexit√§t</th>
            <th>Beschreibung</th>
        </tr>
        <tr>
            <td><strong>Mit Array</strong></td>
            <td>O(V¬≤)</td>
            <td>V = Anzahl Knoten; Lineare Suche nach Minimum</td>
        </tr>
        <tr>
            <td><strong>Mit Binary Heap</strong></td>
            <td>O((V + E) log V)</td>
            <td>E = Anzahl Kanten; Effiziente Minimum-Suche</td>
        </tr>
        <tr>
            <td><strong>Mit Fibonacci Heap</strong></td>
            <td>O(E + V log V)</td>
            <td>Optimal; In Praxis selten verwendet</td>
        </tr>
    </table>

    <h3>Anwendungen</h3>
    <ul>
        <li><strong>Navigation:</strong> Google Maps, GPS-Systeme (k√ºrzester/schnellster Weg)</li>
        <li><strong>Netzwerk-Routing:</strong> OSPF-Protokoll im Internet</li>
        <li><strong>Logistik:</strong> Transportplanung, Lieferrouten optimieren</li>
        <li><strong>Spieleentwicklung:</strong> Pathfinding f√ºr NPCs</li>
        <li><strong>Soziale Netzwerke:</strong> "Degrees of Separation" berechnen</li>
        <li><strong>Robotik:</strong> Bewegungsplanung in bekannten Umgebungen</li>
    </ul>

    <h3>Dijkstra vs. andere Algorithmen</h3>
    <table>
        <tr>
            <th>Algorithmus</th>
            <th>Kantengewichte</th>
            <th>Zeitkomplexit√§t</th>
            <th>Verwendung</th>
        </tr>
        <tr>
            <td><strong>Dijkstra</strong></td>
            <td>Nur nicht-negativ</td>
            <td>O(V¬≤) oder O((V+E) log V)</td>
            <td>K√ºrzeste Wege von einem Startknoten</td>
        </tr>
        <tr>
            <td><strong>Bellman-Ford</strong></td>
            <td>Auch negativ erlaubt</td>
            <td>O(V √ó E)</td>
            <td>Erkennt negative Zyklen</td>
        </tr>
        <tr>
            <td><strong>A* (A-Star)</strong></td>
            <td>Nur nicht-negativ</td>
            <td>Heuristikabh√§ngig</td>
            <td>Schneller mit guter Heuristik</td>
        </tr>
        <tr>
            <td><strong>Floyd-Warshall</strong></td>
            <td>Auch negativ</td>
            <td>O(V¬≥)</td>
            <td>K√ºrzeste Wege zwischen allen Knotenpaaren</td>
        </tr>
    </table>

    <h3>Vorteile und Nachteile</h3>
    <div class="two-column">
        <div class="card card-success">
            <h4>Vorteile ‚úÖ</h4>
            <ul>
                <li>Garantiert k√ºrzeste Wege</li>
                <li>Effizient mit Priority Queue</li>
                <li>Findet alle k√ºrzesten Wege vom Startknoten</li>
                <li>Einfach zu verstehen und implementieren</li>
                <li>Weitverbreitet und gut getestet</li>
            </ul>
        </div>
        <div class="card card-danger">
            <h4>Nachteile ‚ùå</h4>
            <ul>
                <li>Funktioniert nicht mit negativen Gewichten</li>
                <li>Untersucht viele Knoten (keine Heuristik)</li>
                <li>Nur Single-Source (ein Startknoten)</li>
                <li>Langsam bei sehr gro√üen Graphen</li>
                <li>Ben√∂tigt alle Kantengewichte im Voraus</li>
            </ul>
        </div>
    </div>

    <h3>Wichtige Hinweise f√ºr die Pr√ºfung</h3>
    <div class="wichtig">
        <strong>Pr√ºfungsrelevant:</strong>
        <ul>
            <li>Dijkstra Schritt-f√ºr-Schritt auf Papier durchf√ºhren k√∂nnen</li>
            <li>Distanzen korrekt aktualisieren (Relaxation verstehen)</li>
            <li>Vorg√§nger f√ºr Wegrekonstruktion notieren</li>
            <li>Erkennen, wann Algorithmus terminiert</li>
            <li>Unterschied zu anderen Shortest-Path-Algorithmen kennen</li>
            <li>Warum negative Gewichte nicht funktionieren erkl√§ren k√∂nnen</li>
        </ul>
    </div>

    <div class="beispiel">
        <h4>Typische Pr√ºfungsfrage</h4>
        <p><strong>Aufgabe:</strong> "F√ºhre Dijkstra-Algorithmus auf folgendem Graphen aus. Dokumentiere jede Iteration mit Tabelle (Knoten, Distanz, Vorg√§nger, Besucht). Gib den k√ºrzesten Weg von A nach E an."</p>
        
        <p><strong>L√∂sung:</strong></p>
        <ol>
            <li>Erstelle Initialisierungstabelle</li>
            <li>F√ºhre Algorithmus Schritt f√ºr Schritt aus</li>
            <li>Dokumentiere jede Relaxation</li>
            <li>Markiere besuchte Knoten</li>
            <li>Rekonstruiere Pfad √ºber Vorg√§nger</li>
            <li>Gib Gesamtdistanz und Weg an</li>
        </ol>
    </div>

    <h3>Optimierungen</h3>
    <div class="card">
        <p><strong>Bidirektionale Suche:</strong></p>
        <ul>
            <li>Suche gleichzeitig von Start und Ziel</li>
            <li>Stoppe, wenn sich Suchfronten treffen</li>
            <li>Kann Laufzeit halbieren</li>
        </ul>

        <p><strong>A* Algorithmus (Erweiterung):</strong></p>
        <ul>
            <li>Dijkstra + Heuristik (gesch√§tzte Restdistanz)</li>
            <li>f(n) = g(n) + h(n)</li>
            <li>g(n) = bisherige Kosten, h(n) = Heuristik</li>
            <li>Schneller, wenn Zielknoten bekannt</li>
        </ul>
    </div>
</section>

    <!-- k-NN Section -->
    <section id="knn">
        <h2>k-N√§chste-Nachbarn-Verfahren (k-NN)</h2>

        <div class="highlight">
            <strong>k-Nearest Neighbor (k-NN)</strong> ist ein instanzenbasiertes Klassifikationsverfahren. Die Klassifikation erfolgt durch Mehrheitsentscheidung der k √§hnlichsten Trainingsbeispiele. 
        </div>

        <h3>Grundprinzip</h3>
        <p>Bei der Klassifizierung neuer Datens√§tze werden die <strong>√§hnlichsten Beispieldatens√§tze gesucht</strong> (die Nachbarn). Die Klasse, die bei diesen Nachbarn am h√§ufigsten auftritt, wird der neuen Instanz zugeordnet.</p>

        <div class="card">
            <p><strong>Charakteristika:</strong></p>
            <ul>
                <li>üîπ <strong>Lazy Learning</strong>: Kein eigentliches Training, nur Abspeichern der Beispiele </li>
                <li>üîπ <strong>Instanzenbasiert</strong>: Trainingsdaten selbst repr√§sentieren das Wissen </li>
                <li>üîπ <strong>Nichtparametrisch</strong>: Keine Annahmen √ºber Datenverteilung </li>
                <li>üîπ Funktioniert f√ºr quantitative UND qualitative Merkmale </li>
            </ul>
        </div>

        <h3>Algorithmus-Schritte</h3>
        <div class="card card-success">
            <ol>
                <li><strong>Pr√ºfung auf gleiche Dimension</strong> aller Punkte </li>
                <li><strong>Sicherstellung eines g√ºltigen k-Werts</strong> (k ‚â§ Anzahl Trainingspunkte) </li>
                <li><strong>Berechnung der Distanzen</strong> zu allen Trainingspunkten </li>
                <li><strong>Sortierung der Distanzen</strong> (aufsteigend)</li>
                <li><strong>Auswahl der k kleinsten Distanzen</strong></li>
                <li><strong>Mehrheitsentscheidung</strong>: H√§ufigste Klasse unter den k Nachbarn gewinnt </li>
                <li><strong>R√ºckgabe</strong> der vorhergesagten Klasse</li>
            </ol>
        </div>

        <h3>Distanzma√üe</h3>
        
        <h4>1. Euklidische Distanz (am h√§ufigsten verwendet)</h4>
        <div class="formula">
dist<sub>E</sub>(v,w) = ‚àö(Œ£(v<sub>i</sub> - w<sub>i</sub>)¬≤)
</div>
<p>Die Summe der quadrierten Differenzen aller Attributwerte. Entspricht der "Luftlinie" zwischen zwei Punkten. ibm</p>
        <h4>2. Manhattan-Distanz</h4>
        <div class="formula">
dist<sub>M</sub>(v,w) = Œ£|v<sub>i</sub> - w<sub>i</sub>|
</div>
<p>Die Summe der absoluten Differenzen. Entspricht dem Weg entlang von Stra√üen in einer Stadt. ibm</p>
        <h4>3. Hamming-Distanz (f√ºr kategorische Daten)</h4>
        <div class="formula">
dist<sub>H</sub>(v,w) = count(v<sub>i</sub> ‚â† w<sub>i</sub>)
</div>
<p>Anzahl der Attributwerte, bei denen v und w unterschiedlich sind. Gitlab</p>
        <h3>Normalisierung</h3>
        <div class="wichtig">
            Bei stark unterschiedlichen Wertebereichen ist eine <strong>Normalisierung erforderlich</strong>, um Ungleichgewichtung zu vermeiden!
        </div>

        <div class="formula">
x<sub>normalisiert</sub> = (x - x<sub>min</sub>) / (x<sub>max</sub> - x<sub>min</sub>)
</div>
        <div class="beispiel">
            <h4>Beispiel: Warum Normalisierung wichtig ist</h4>
            <p>Gegeben: Datensatz mit Attributen Alter (20-60) und Eigenheim (0-1)</p>
            <p>Ohne Normalisierung: Das Alter dominiert die Distanzberechnung komplett!</p>
            <ul>
                <li>Distanz im Alter zwischen 26 und 59: 33</li>
                <li>Distanz beim Eigenheim: maximal 1</li>
            </ul>
            <p><strong>L√∂sung:</strong> Normalisierung aller Attribute ins Intervall [0,1]</p>
        </div>

        <h3>Wahl von k</h3>
        <table>
            <tr>
                <th>k-Wert</th>
                <th>Eigenschaften</th>
                <th>Probleme</th>
            </tr>
            <tr>
                <td><strong>k = 1</strong></td>
                <td>Nur der n√§chste Nachbar z√§hlt </td>
                <td>‚ùå Sehr sensitiv gegen√ºber Ausrei√üern und Rauschen<br>‚ùå Gefahr von Overfitting</td>
            </tr>
            <tr>
                <td><strong>k klein (2-5)</strong></td>
                <td>Wenige Nachbarn beeinflussen Entscheidung</td>
                <td>‚ö†Ô∏è Noch anf√§llig f√ºr Rauschen</td>
            </tr>
            <tr>
                <td><strong>k optimal (‚àön)</strong></td>
                <td>Faustregel: k = ‚àö(Anzahl Trainingsdaten)</td>
                <td>‚úÖ Guter Kompromiss</td>
            </tr>
            <tr>
                <td><strong>k gro√ü</strong></td>
                <td>Viele Nachbarn beeinflussen</td>
                <td>‚ùå Punkte mit gro√üem Abstand beeinflussen Entscheidung<br>‚ùå Wird langsam<br>‚ùå Gefahr von Underfitting </td>
            </tr>
        </table>

        <div class="wichtig">
            Bei zwei Klassen: <strong>k ungerade w√§hlen</strong>, um Unentschieden zu vermeiden! 
        </div>

        <h3>Vorteile und Nachteile</h3>
        <div class="two-column">
            <div class="card card-success">
                <h4>Vorteile ‚úÖ</h4>
                <ul>
                    <li>Sehr einfach zu verstehen und implementieren </li>
                    <li>Keine Trainingsphase erforderlich</li>
                    <li>Funktioniert f√ºr quantitative und qualitative Merkmale </li>
                    <li>Liefert oft gute Ergebnisse </li>
                    <li>Flexibel einsetzbar</li>
                </ul>
            </div>
            <div class="card card-danger">
                <h4>Nachteile ‚ùå</h4>
                <ul>
                    <li>Aufw√§ndige Klassifikationsphase </li>
                    <li>Hoher Speicher- und Rechenaufwand bei vielen Trainingsdaten </li>
                    <li>"Curse of Dimensionality" bei hochdimensionalen R√§umen</li>
                    <li>Liefert kein explizites Wissen √ºber Klassen </li>
                    <li>Sensitiv gegen√ºber Ausrei√üern</li>
                </ul>
            </div>
        </div>

        <h3>Beispielaufgabe</h3>
        <div class="beispiel">
            <h4>Klassifikation durchf√ºhren</h4>
            <p><strong>Gegeben:</strong> 8 Trainingspunkte mit Attributen Alter, Familienstand, Ausbildung, Eigenheim und Einkommensniveau (hoch/niedrig). </p>
            <p><strong>Aufgabe:</strong> Klassifiziere einen 26-j√§hrigen, verheirateten Akademiker ohne Eigenheim mit k=2. </p>
            
            <p><strong>L√∂sungsschritte:</strong></p>
            <ol>
                <li>Normalisiere das Attribut Alter: Alter<sub>norm</sub> = (26 - 20) / (60 - 20) = 0.15</li>
                <li>Berechne Distanzen zu allen 8 Trainingspunkten (mit normalisierten Werten)</li>
                <li>Sortiere Distanzen aufsteigend</li>
                <li>W√§hle die 2 Datens√§tze mit kleinster Distanz</li>
                <li>Z√§hle Klassen: z.B. 2x "hoch" ‚Üí Vorhersage: "hohes Einkommen"</li>
            </ol>
        </div>

        <h3>Pr√ºfungsrelevante Begriffe</h3>
        <ul>
            <li><strong>Instanzenbasiertes Lernen</strong> (instance-based learning)</li>
            <li><strong>Lazy Learning</strong> (tr√§ges Lernen)</li>
            <li><strong>Merkmalsvektor</strong> (feature vector)</li>
            <li><strong>Mehrheitsentscheidung</strong> (majority vote)</li>
            <li><strong>Abstandsma√üe</strong> (distance metrics)</li>
            <li><strong>Normalisierung</strong> (normalization)</li>
        </ul>
    </section>

    <!-- K-Means Section -->
    <section id="kmeans">
        <h2>K-Means Clusteranalyse</h2>

        <div class="highlight">
            <strong>K-Means</strong> ist ein un√ºberwachtes Lernverfahren zur Clusteranalyse. Es teilt Daten in k Cluster ein, sodass Punkte innerhalb eines Clusters m√∂glichst √§hnlich und Cluster untereinander m√∂glichst verschieden sind. 
        </div>

        <h3>Grundkonzept</h3>
        <p>K-Means ist ein <strong>un√ºberwachtes Lernverfahren</strong> ‚Äì die Trainingsdaten haben keine vordefinierten Labels. Das Ziel ist es, k Clusterzentren (Zentroide) zu finden, um die Daten optimal in k Cluster aufzuteilen.</p>

        <div class="card">
            <p><strong>Charakteristika:</strong></p>
            <ul>
                <li>üîπ <strong>Un√ºberwachtes Lernen</strong>: Keine vordefinierten Klassen </li>
                <li>üîπ Jeder Datenpunkt geh√∂rt zu genau einem Cluster </li>
                <li>üîπ Cluster werden durch <strong>Zentroide</strong> (Schwerpunkte) repr√§sentiert</li>
                <li>üîπ Iterativer Optimierungsprozess</li>
            </ul>
        </div>

        <h3>Algorithmus-Schritte</h3>
        <div class="card card-success">
            <h4>Schritt 1: Initialisierung</h4>
            <ul>
                <li>W√§hle die Anzahl der Cluster <strong>k</strong> </li>
                <li>Platziere k Zentroide zuf√§llig im Datenraum (oder verwende k-means++ Methode) </li>
            </ul>

            <h4>Schritt 2: Zuordnung (Assignment)</h4>
            <ul>
                <li>F√ºr jeden Datenpunkt: Berechne Distanz zu allen k Zentroiden </li>
                <li>Ordne Punkt dem n√§chstgelegenen Zentroid zu </li>
                <li>Gib dem Punkt das Label des Zentroids </li>
            </ul>

            <h4>Schritt 3: Update (Neuberechnung)</h4>
            <ul>
                <li>F√ºr jeden Cluster: Berechne neuen Zentroid als Schwerpunkt aller Punkte im Cluster</li>
                <li>Neuer Zentroid = Mittelwert aller Punktkoordinaten im Cluster</li>
            </ul>

            <h4>Schritt 4: Konvergenzpr√ºfung</h4>
            <ul>
                <li>Haben sich die Zentroide (signifikant) bewegt?</li>
                <li><strong>NEIN</strong> ‚Üí STOP, Algorithmus konvergiert</li>
                <li><strong>JA</strong> ‚Üí Zur√ºck zu Schritt 2</li>
            </ul>
        </div>

        <h3>Formeln und Berechnungen</h3>

        <h4>Zentroid-Berechnung</h4>
        <div class="formula">
Zentroid Œº<sub>i</sub> = (1/n) √ó Œ£(x<sub>j</sub>)
wobei n = Anzahl Punkte im Cluster C<sub>i</sub>
x<sub>j</sub> = einzelne Datenpunkte
</div>
        <div class="beispiel">
            <h4>Beispiel: Zentroid berechnen</h4>
            <p>Gegeben: 3 Punkte im Cluster: (2,3), (4,5), (6,7)</p>
            <p><strong>Berechnung:</strong></p>
            <ul>
                <li>x-Koordinate: (2+4+6)/3 = 4</li>
                <li>y-Koordinate: (3+5+7)/3 = 5</li>
            </ul>
            <p><strong>Neuer Zentroid: (4, 5)</strong></p>
        </div>

        <h4>Euklidische Distanz</h4>
        <div class="formula">
d(p,q) = ‚àö[(p‚ÇÅ-q‚ÇÅ)¬≤ + (p‚ÇÇ-q‚ÇÇ)¬≤ + ... + (p‚Çô-q‚Çô)¬≤]
= ‚àö[Œ£(p·µ¢ - q·µ¢)¬≤]
</div>
        <h4>Zielfunktion (Within-Cluster Sum of Squares - WCSS)</h4>
        <div class="formula">
J = Œ£(i=1 bis k) Œ£(x<sub>j</sub> ‚àà C<sub>i</sub>) ||x<sub>j</sub> - Œº<sub>i</sub>||¬≤
Ziel: J minimieren (Summe der quadrierten Abst√§nde innerhalb der Cluster)
</div>
        <h3>Konvergenzkriterien</h3>
        <table>
            <tr>
                <th>Kriterium</th>
                <th>Beschreibung</th>
            </tr>
            <tr>
                <td><strong>Keine Neuzuordnung</strong></td>
                <td>Cluster-Zuordnungen √§ndern sich nicht mehr (h√§ufigstes Kriterium)</td>
            </tr>
            <tr>
                <td><strong>Zentroid-Stabilit√§t</strong></td>
                <td>Zentroide bewegen sich nicht mehr (√Ñnderung \u003c Schwellenwert Œµ)</td>
            </tr>
            <tr>
                <td><strong>Maximale Iterationen</strong></td>
                <td>Vordefinierte Anzahl Durchl√§ufe erreicht (z.B. 10 Iterationen)</td>
            </tr>
            <tr>
                <td><strong>Minimale Verbesserung</strong></td>
                <td>Abnahme der Zielfunktion J unter Schwellenwert</td>
            </tr>
        </table>

        <h3>Optimale Clusterzahl k bestimmen</h3>

        <h4>Elbow-Methode</h4>
        <div class="card">
            <ol>
                <li>F√ºhre K-Means f√ºr verschiedene k-Werte aus (z.B. k=1 bis 10)</li>
                <li>Berechne WCSS (Inertia) f√ºr jeden k-Wert</li>
                <li>Plotte k gegen WCSS</li>
                <li>Suche den "Ellbogen"-Punkt: Stelle, wo WCSS-Abnahme sich stark verlangsamt</li>
                <li>Dieses k ist optimal</li>
            </ol>
        </div>

        <h4>Silhouetten-Koeffizient</h4>
        <div class="formula">
Silhouette = (b - a) / max(a, b)
a = durchschnittliche Distanz zu Punkten im eigenen Cluster
b = durchschnittliche Distanz zum n√§chsten Cluster
Wertebereich: -1 bis +1
+1: Punkt liegt gut im eigenen Cluster
0: Punkt liegt an Clustergrenze
-1: Punkt ist falsch zugeordnet
</div>
        <h3>Anwendungen</h3>
        <ul>
            <li><strong>Kundensegmentierung</strong>: Gruppierung von Kunden mit √§hnlichem Kaufverhalten</li>
            <li><strong>Bildkompression</strong>: Reduktion der Farbanzahl durch Clustering im RGB-Raum</li>
            <li><strong>Dokumenten-Clustering</strong>: Gruppierung √§hnlicher Dokumente oder Texte</li>
            <li><strong>Anomalieerkennung</strong>: Identifikation von Ausrei√üern (Spam, Betrug)</li>
            <li><strong>Marktforschung</strong>: Marktsegmentierung f√ºr gezielte Kampagnen</li>
            <li><strong>Qualit√§tskontrolle</strong>: Produktklassifizierung nach Qualit√§tsstufen</li>
        </ul>

        <div class="beispiel">
            <h4>Beispiel: Bildkompression</h4>
            <p><strong>Originalbild:</strong> 16,7 Millionen Farben (RGB: 256¬≥)</p>
            <p><strong>Nach K-Means mit k=15:</strong> Nur noch 15 Farben</p>
            <p><strong>Ergebnis:</strong> 60% Speicherreduktion, Kerninhalt bleibt erkennbar</p>
            <p><strong>Methode:</strong> Jeder Pixel = Datenpunkt (R,G,B). K-Means findet 15 repr√§sentative Farben.</p>
        </div>

        <h3>Vorteile und Nachteile</h3>
        <div class="two-column">
            <div class="card card-success">
                <h4>Vorteile ‚úÖ</h4>
                <ul>
                    <li>Sehr schnell und effizient</li>
                    <li>Skalierbar f√ºr gro√üe Datenmengen</li>
                    <li>Einfach zu verstehen und implementieren</li>
                    <li>Funktioniert gut bei sph√§rischen Clustern</li>
                    <li>Geringe Speicher- und Rechenanforderungen</li>
                </ul>
            </div>
            <div class="card card-danger">
                <h4>Nachteile ‚ùå</h4>
                <ul>
                    <li>k muss vorher festgelegt werden</li>
                    <li>Ergebnis h√§ngt von Initialisierung ab</li>
                    <li>Sensitiv gegen√ºber Ausrei√üern</li>
                    <li>Funktioniert nur f√ºr sph√§rische Cluster</li>
                    <li>Nur numerische Daten (kategorische m√ºssen encodiert werden)</li>
                    <li>Keine Garantie f√ºr globales Optimum</li>
                </ul>
            </div>
        </div>

        <h3>Wichtige Hinweise f√ºr die Pr√ºfung</h3>
        <div class="wichtig">
            <strong>Datenaufbereitung ist essentiell:</strong>
            <ul>
                <li>Alle Features normalisieren/standardisieren</li>
                <li>Ausrei√üer vorher entfernen</li>
                <li>Kategorische Variablen m√ºssen encodiert werden</li>
                <li>Keine fehlenden Werte erlaubt</li>
            </ul>
        </div>

        <div class="wichtig">
            <strong>Initialisierung verbessern:</strong>
            <ul>
                <li>Verwende k-means++ statt zuf√§lliger Initialisierung</li>
                <li>F√ºhre Algorithmus mehrmals aus (verschiedene Starts)</li>
                <li>W√§hle Ergebnis mit niedrigster Inertia</li>
            </ul>
        </div>
    </section>

    <!-- MinMax Section -->
    <section id="minmax">
        <h2>Min-Max-Algorithmus</h2>

        <div class="highlight">
            <strong>Minimax</strong> ist ein rekursiver Entscheidungsalgorithmus f√ºr 2-Personen-Nullsummenspiele. Er minimiert den maximalen Verlust und maximiert den minimalen Gewinn unter der Annahme optimalen Spiels beider Spieler.
        </div>

        <h3>Grundkonzept</h3>
        <p>Der Minimax-Algorithmus wird in der Spieltheorie und bei Computerspielen eingesetzt. Er ist besonders relevant f√ºr:</p>
        <ul>
            <li>Rundenbasierte Spiele (Schach, Dame, Tic-Tac-Toe)</li>
            <li>Spiele mit <strong>vollst√§ndiger Information</strong> (keine versteckten Karten)</li>
            <li><strong>Nullsummenspiele</strong>: Gewinn des einen = Verlust des anderen</li>
        </ul>

        <h3>Die zwei Spieler</h3>
        <div class="two-column">
            <div class="card card-success">
                <h4>Maximierer (Max)</h4>
                <ul>
                    <li>M√∂chte den Score <strong>maximieren</strong></li>
                    <li>W√§hlt Zug mit h√∂chstem Nutzen</li>
                    <li>Repr√§sentiert die KI oder den Spieler</li>
                    <li>Nimmt an, Gegner spielt optimal</li>
                </ul>
            </div>
            <div class="card card-danger">
                <h4>Minimierer (Min)</h4>
                <ul>
                    <li>M√∂chte den Score des Maximierers <strong>minimieren</strong></li>
                    <li>W√§hlt Zug mit niedrigstem Nutzen f√ºr Max</li>
                    <li>Repr√§sentiert den Gegner</li>
                    <li>Nimmt ebenfalls optimales Spiel an</li>
                </ul>
            </div>
        </div>

        <h3>Spielbaum-Struktur</h3>
        <div class="card">
            <p><strong>Komponenten eines Spielbaums:</strong></p>
            <ul>
                <li><strong>Wurzelknoten (Root)</strong>: Aktueller Spielzustand</li>
                <li><strong>Innere Knoten</strong>: Zwischenzust√§nde des Spiels</li>
                <li><strong>Blattknoten (Terminal Nodes)</strong>: Endzust√§nde (Gewinn/Verlust/Unentschieden)</li>
                <li><strong>Kanten</strong>: M√∂gliche Z√ºge/Aktionen</li>
                <li><strong>Tiefe (Depth)</strong>: Anzahl Z√ºge vorausschauend (gemessen in "Plies")</li>
                <li><strong>Verzweigungsfaktor (Branching Factor)</strong>: Durchschnittliche Anzahl legaler Z√ºge</li>
            </ul>
        </div>

        <h3>Algorithmus-Schritte</h3>
        <div class="card card-success">
            <h4>Schritt 1: Spielbaum generieren</h4>
            <p>Erstelle Baumstruktur aller m√∂glichen Z√ºge vom aktuellen Spielzustand aus.</p>

            <h4>Schritt 2: Terminale Zust√§nde bewerten</h4>
            <p>Weise Nutzenwerte den Blattknoten zu:</p>
            <ul>
                <li>+1 (oder +‚àû): Maximierer gewinnt</li>
                <li>0: Unentschieden</li>
                <li>-1 (oder -‚àû): Minimierer gewinnt</li>
            </ul>

            <h4>Schritt 3: Werte nach oben propagieren (Backtracking)</h4>
            <p>F√ºr jeden inneren Knoten:</p>
            <ul>
                <li><strong>Max-Knoten</strong>: W√§hle MAXIMUM der Kindknoten</li>
                <li><strong>Min-Knoten</strong>: W√§hle MINIMUM der Kindknoten</li>
            </ul>

            <h4>Schritt 4: Optimalen Zug w√§hlen</h4>
            <p>Am Wurzelknoten: Maximierer w√§hlt den Zug mit dem h√∂chsten Wert.</p>
        </div>

        <h3>Mathematische Formeln</h3>

        <h4>F√ºr Maximierer</h4>
        <div class="formula">
Max(s) = max[a ‚àà A(s)] Min(Result(s, a))
s = aktueller Zustand
A(s) = Menge aller m√∂glichen Aktionen
Result(s, a) = Resultatszustand nach Aktion a
</div>
        <h4>F√ºr Minimierer</h4>
        <div class="formula">
Min(s) = min[a ‚àà A(s)] Max(Result(s, a))
</div>
        <h4>Nutzenfunktion f√ºr terminale Zust√§nde</h4>
        <div class="formula">
Utility(s) = {
+1  wenn Maximierer gewinnt
0  bei Unentschieden
-1  wenn Minimierer gewinnt
}
</div>
        <h3>Beispiel: Minimax-Baum evaluieren</h3>
        <div class="beispiel">
            <h4>Beispiel mit Terminalwerten [3, 5, 2, 9]</h4>
            <pre>
            Maximierer (Root)
           /                \
     Minimierer            Minimierer
     /      \             /      \
    3       5           2        9
            </pre>

            <p><strong>Evaluation:</strong></p>
            <ol>
                <li><strong>Minimierer LINKS:</strong> min(3, 5) = 3</li>
                <li><strong>Minimierer RECHTS:</strong> min(2, 9) = 2</li>
                <li><strong>Maximierer:</strong> max(3, 2) = 3</li>
            </ol>
            <p><strong>Optimaler Wert: 3 (Maximierer geht nach LINKS)</strong></p>
            <p><em>Hinweis:</em> Obwohl der Wert 9 existiert, wird der Minimierer ihn nie w√§hlen!</p>
        </div>

        <h3>Alpha-Beta-Pruning (Optimierung)</h3>
        <p>Alpha-Beta-Pruning ist eine Optimierungstechnik, die Zweige abschneidet, die das Endergebnis nicht beeinflussen k√∂nnen.</p>

        <h4>Parameter</h4>
        <div class="two-column">
            <div class="card">
                <h4>Alpha (Œ±)</h4>
                <p>Bester Wert f√ºr den Maximierer bisher gefunden</p>
                <p>Initialisierung: Œ± = -‚àû</p>
                <p>Wird beim Maximierer aktualisiert</p>
            </div>
            <div class="card">
                <h4>Beta (Œ≤)</h4>
                <p>Bester Wert f√ºr den Minimierer bisher gefunden</p>
                <p>Initialisierung: Œ≤ = +‚àû</p>
                <p>Wird beim Minimierer aktualisiert</p>
            </div>
        </div>

        <h4>Pruning-Bedingung</h4>
        <div class="formula">
Wenn Œ± ‚â• Œ≤, dann schneide verbleibende Zweige ab (Pruning)
</div>
        <h4>Funktionsweise</h4>
        <div class="card card-warning">
            <p><strong>Bei Maximierer-Knoten:</strong></p>
            <ul>
                <li>Aktualisiere Œ± mit bestem gefundenen Wert</li>
                <li>Wenn Œ± ‚â• Œ≤: <strong>PRUNE</strong> (Minimierer wird diesen Pfad nie w√§hlen)</li>
            </ul>

            <p><strong>Bei Minimierer-Knoten:</strong></p>
            <ul>
                <li>Aktualisiere Œ≤ mit bestem gefundenen Wert</li>
                <li>Wenn Œ≤ ‚â§ Œ±: <strong>PRUNE</strong> (Maximierer wird diesen Pfad nie zulassen)</li>
            </ul>
        </div>

        <h4>Vorteile von Alpha-Beta-Pruning</h4>
        <ul>
            <li>‚úÖ <strong>Effizienz:</strong> Reduziert Anzahl zu evaluierender Knoten erheblich</li>
            <li>‚úÖ Erm√∂glicht tiefere Suche mit gleichen Ressourcen</li>
            <li>‚úÖ <strong>Optimale Entscheidungen:</strong> Garantiert gleiches Ergebnis wie Minimax</li>
            <li>‚úÖ Kann Millionen Positionen einsparen</li>
        </ul>

        <h3>Pseudocode</h3>
        <pre>
function minimax(state, depth, maximizingPlayer):
if depth = 0 or state is terminal:
return utility(state)
if maximizingPlayer:
    maxEval = -‚àû
    for action in actions(state):
        eval = minimax(result(state, action), depth-1, False)
        maxEval = max(maxEval, eval)
    return maxEval
else:
    minEval = +‚àû
    for action in actions(state):
        eval = minimax(result(state, action), depth-1, True)
        minEval = min(minEval, eval)
    return minEval
        </pre>

        <h3>Komplexit√§t</h3>
        <table>
            <tr>
                <th>Variante</th>
                <th>Zeitkomplexit√§t</th>
                <th>Beschreibung</th>
            </tr>
            <tr>
                <td><strong>Minimax ohne Pruning</strong></td>
                <td>O(b<sup>d</sup>)</td>
                <td>b = Verzweigungsfaktor, d = Tiefe</td>
            </tr>
            <tr>
                <td><strong>Alpha-Beta (optimal)</strong></td>
                <td>O(b<sup>d/2</sup>)</td>
                <td>Verdoppelt effektiv die Suchtiefe</td>
            </tr>
            <tr>
                <td><strong>Raumkomplexit√§t</strong></td>
                <td>O(bd)</td>
                <td>Analog zu Tiefensuche (DFS)</td>
            </tr>
        </table>

        <h3>Anwendungen</h3>
        <ul>
            <li><strong>Schach:</strong> IBM Deep Blue besiegte 1997 Weltmeister Garry Kasparov</li>
            <li><strong>Dame (Checkers):</strong> Chinook gewann 1994 Weltmeisterschaft</li>
            <li><strong>Tic-Tac-Toe:</strong> Perfektes Spiel f√ºhrt immer zu Unentschieden</li>
            <li><strong>Othello/Reversi:</strong> Effektiv mit Evaluationsfunktionen</li>
            <li><strong>AlphaZero (DeepMind):</strong> Kombination von Minimax mit Deep Learning</li>
        </ul>

        <h3>Vorteile und Nachteile</h3>
        <div class="two-column">
            <div class="card card-success">
                <h4>Vorteile ‚úÖ</h4>
                <ul>
                    <li>Garantiert optimale Entscheidung</li>
                    <li>Einfach zu verstehen</li>
                    <li>Deterministisch</li>
                    <li>Vollst√§ndig (findet L√∂sung wenn vorhanden)</li>
                    <li>Gut f√ºr Spiele mit perfekter Information</li>
                </ul>
            </div>
            <div class="card card-danger">
                <h4>Nachteile ‚ùå</h4>
                <ul>
                    <li><strong>Exponenzielle Komplexit√§t O(b<sup>d</sup>)</strong></li>
                    <li>Unpraktisch f√ºr Spiele mit tiefem/komplexem Baum</li>
                    <li>Tiefenbegrenzung notwendig ‚Üí suboptimale Entscheidungen</li>
                    <li>Nimmt deterministische Ergebnisse an</li>
                    <li>Effektivit√§t h√§ngt von Zugreihenfolge ab (Alpha-Beta)</li>
                    <li>Kein Lernen aus Erfahrung</li>
                </ul>
            </div>
        </div>

        <h3>Wichtig f√ºr die Pr√ºfung</h3>
        <div class="wichtig">
            <ul>
                <li>Minimax-Baum Schritt f√ºr Schritt evaluieren k√∂nnen</li>
                <li>Verstehen, wann Alpha-Beta-Cutoffs auftreten</li>
                <li>Unterschied zwischen Maximierer und Minimierer erkl√§ren k√∂nnen</li>
                <li>Komplexit√§tsanalyse kennen (O(b<sup>d</sup>) vs. O(b<sup>d/2</sup>))</li>
                <li>Annahme optimalen Spiels beider Spieler verstehen</li>
                <li>Anwendungsbeispiele kennen (Deep Blue, Schach, Dame)</li>
            </ul>
        </div>
    </section>

    <!-- Code-Implementierungen Section (f√ºge dies nach der Zusammenfassung ein) -->
<section id="implementierungen">
    <h2>üîß Code-Implementierungen</h2>
    
    <div class="highlight">
        <strong>Wichtig f√ºr die Klassenarbeit:</strong> Diese Implementierungen zeigen, dass du die Algorithmen nicht nur verstehst, sondern auch programmieren kannst. Achte auf die Struktur und Kommentare!
    </div>

    <!-- k-NN Implementierung -->
    <h3>k-NN Implementierung</h3>
    
    <h4>Pseudocode k-NN</h4>
    <pre>
ALGORITHMUS k-NearestNeighbor(trainingData, testPoint, k)
    // Eingabe: trainingData = Liste von gelabelten Punkten
    //          testPoint = zu klassifizierender Punkt
    //          k = Anzahl Nachbarn
    // Ausgabe: vorhergesagte Klasse
    
    distances = []
    
    F√úR JEDEN point IN trainingData:
        distance = calculateEuclideanDistance(testPoint, point)
        distances.add({distance, point.label})
    ENDE F√úR
    
    // Sortiere nach Distanz aufsteigend
    distances.sortByDistance()
    
    // W√§hle k n√§chste Nachbarn
    kNeighbors = distances.take(k)
    
    // Z√§hle Klassenh√§ufigkeiten
    classCount = {}
    F√úR JEDEN neighbor IN kNeighbors:
        classCount[neighbor.label]++
    ENDE F√úR
    
    // Gib h√§ufigste Klasse zur√ºck
    RETURN classCount.getMostFrequent()
ENDE ALGORITHMUS

FUNKTION calculateEuclideanDistance(point1, point2)
    sum = 0
    F√úR i = 0 BIS point1.dimensions:
        sum += (point1[i] - point2[i])¬≤
    ENDE F√úR
    RETURN sqrt(sum)
ENDE FUNKTION
    </pre>

    <h4>Java-Implementierung k-NN</h4>
    <pre>
import java.util.*;

public class KNearestNeighbor {
    // Klasse f√ºr Datenpunkte
    class DataPoint {
        double[] features;  // Merkmale des Punkts
        String label;       // Klassenlabel
        
        public DataPoint(double[] features, String label) {
            this.features = features;
            this.label = label;
        }
    }
    
    // Klasse f√ºr Distanz-Label Paare
    class DistanceLabelPair implements Comparable<DistanceLabelPair> {
        double distance;
        String label;
        
        public DistanceLabelPair(double distance, String label) {
            this.distance = distance;
            this.label = label;
        }
        
        @Override
        public int compareTo(DistanceLabelPair other) {
            return Double.compare(this.distance, other.distance);
        }
    }
    
    private List<DataPoint> trainingData;
    
    public KNearestNeighbor(List<DataPoint> trainingData) {
        this.trainingData = trainingData;
    }
    
    // Hauptmethode: Klassifiziert einen neuen Punkt
    public String classify(double[] testPoint, int k) {
        // Validierung
        if (k > trainingData.size()) {
            throw new IllegalArgumentException("k darf nicht gr√∂√üer als Trainingsdaten sein");
        }
        
        // Berechne Distanzen zu allen Trainingspunkten
        List<DistanceLabelPair> distances = new ArrayList<>();
        
        for (DataPoint trainPoint : trainingData) {
            double distance = euclideanDistance(testPoint, trainPoint.features);
            distances.add(new DistanceLabelPair(distance, trainPoint.label));
        }
        
        // Sortiere nach Distanz
        Collections.sort(distances);
        
        // W√§hle k n√§chste Nachbarn
        Map<String, Integer> classVotes = new HashMap<>();
        for (int i = 0; i < k; i++) {
            String label = distances.get(i).label;
            classVotes.put(label, classVotes.getOrDefault(label, 0) + 1);
        }
        
        // Finde Klasse mit meisten Stimmen
        String prediction = "";
        int maxVotes = 0;
        for (Map.Entry<String, Integer> entry : classVotes.entrySet()) {
            if (entry.getValue() > maxVotes) {
                maxVotes = entry.getValue();
                prediction = entry.getKey();
            }
        }
        
        return prediction;
    }
    
    // Berechnet euklidische Distanz
    private double euclideanDistance(double[] point1, double[] point2) {
        if (point1.length != point2.length) {
            throw new IllegalArgumentException("Punkte m√ºssen gleiche Dimension haben");
        }
        
        double sum = 0.0;
        for (int i = 0; i < point1.length; i++) {
            sum += Math.pow(point1[i] - point2[i], 2);
        }
        return Math.sqrt(sum);
    }
    
    // Normalisierung der Daten (Min-Max Normalisierung)
    public static double[][] normalize(double[][] data) {
        int rows = data.length;
        int cols = data[0].length;
        double[][] normalized = new double[rows][cols];
        
        // Finde Min und Max f√ºr jede Spalte
        for (int j = 0; j < cols; j++) {
            double min = Double.MAX_VALUE;
            double max = Double.MIN_VALUE;
            
            for (int i = 0; i < rows; i++) {
                min = Math.min(min, data[i][j]);
                max = Math.max(max, data[i][j]);
            }
            
            // Normalisiere Spalte
            for (int i = 0; i < rows; i++) {
                if (max - min != 0) {
                    normalized[i][j] = (data[i][j] - min) / (max - min);
                } else {
                    normalized[i][j] = 0; // Falls alle Werte gleich
                }
            }
        }
        
        return normalized;
    }
    
    // Beispiel-Hauptmethode
    public static void main(String[] args) {
        KNearestNeighbor knn = new KNearestNeighbor(new ArrayList<>());
        
        // Erstelle Trainingsdaten
        List<DataPoint> training = new ArrayList<>();
        training.add(knn.new DataPoint(new double[]{2, 3}, "A"));
        training.add(knn.new DataPoint(new double[]{5, 4}, "B"));
        training.add(knn.new DataPoint(new double[]{9, 6}, "B"));
        training.add(knn.new DataPoint(new double[]{4, 7}, "A"));
        training.add(knn.new DataPoint(new double[]{8, 1}, "B"));
        training.add(knn.new DataPoint(new double[]{7, 2}, "B"));
        
        knn = new KNearestNeighbor(training);
        
        // Klassifiziere neuen Punkt
        double[] testPoint = {5, 5};
        int k = 3;
        
        String prediction = knn.classify(testPoint, k);
        System.out.println("Vorhersage f√ºr Punkt [5,5] mit k=3: " + prediction);
    }
}
    </pre>

    <!-- K-Means Implementierung -->
    <h3>K-Means Implementierung</h3>
    
    <h4>Pseudocode K-Means</h4>
    <pre>
ALGORITHMUS KMeans(data, k, maxIterations)
    // Eingabe: data = Liste von Datenpunkten
    //          k = Anzahl Cluster
    //          maxIterations = maximale Iterationen
    // Ausgabe: Cluster-Zuordnungen und Zentroide
    
    // Schritt 1: Initialisiere k zuf√§llige Zentroide
    centroids = selectRandomCentroids(data, k)
    
    F√úR iteration = 1 BIS maxIterations:
        // Schritt 2: Zuordnung (Assignment)
        clusters = createEmptyClusters(k)
        
        F√úR JEDEN point IN data:
            nearestCentroid = -1
            minDistance = INFINITY
            
            F√úR i = 0 BIS k-1:
                distance = calculateDistance(point, centroids[i])
                WENN distance < minDistance:
                    minDistance = distance
                    nearestCentroid = i
                ENDE WENN
            ENDE F√úR
            
            clusters[nearestCentroid].add(point)
        ENDE F√úR
        
        // Schritt 3: Update (Neuberechnung der Zentroide)
        oldCentroids = centroids.copy()
        
        F√úR i = 0 BIS k-1:
            WENN clusters[i] ist nicht leer:
                centroids[i] = calculateMean(clusters[i])
            ENDE WENN
        ENDE F√úR
        
        // Schritt 4: Konvergenzpr√ºfung
        WENN centroids == oldCentroids:
            BREAK  // Algorithmus konvergiert
        ENDE WENN
    ENDE F√úR
    
    RETURN clusters, centroids
ENDE ALGORITHMUS

FUNKTION calculateMean(points)
    dimensions = points[0].length
    mean = array[dimensions]
    
    F√úR JEDE dimension:
        sum = 0
        F√úR JEDEN point IN points:
            sum += point[dimension]
        ENDE F√úR
        mean[dimension] = sum / points.size
    ENDE F√úR
    
    RETURN mean
ENDE FUNKTION
    </pre>

    <h4>Java-Implementierung K-Means</h4>
    <pre>
import java.util.*;
import java.util.stream.*;

public class KMeans {
    private int k;                      // Anzahl Cluster
    private int maxIterations;          // Max. Iterationen
    private double[][] centroids;       // Cluster-Zentroide
    private List<Integer> assignments;  // Cluster-Zuordnungen
    
    public KMeans(int k, int maxIterations) {
        this.k = k;
        this.maxIterations = maxIterations;
    }
    
    // Hauptmethode: F√ºhrt K-Means aus
    public void fit(double[][] data) {
        int n = data.length;        // Anzahl Datenpunkte
        int dimensions = data[0].length;  // Anzahl Dimensionen
        
        // Initialisiere zuf√§llige Zentroide
        centroids = initializeCentroids(data);
        assignments = new ArrayList<>(Collections.nCopies(n, -1));
        
        // Iterativer K-Means Algorithmus
        for (int iteration = 0; iteration < maxIterations; iteration++) {
            boolean changed = false;
            
            // Schritt 1: Assignment - Ordne jeden Punkt dem n√§chsten Zentroid zu
            for (int i = 0; i < n; i++) {
                int nearestCluster = findNearestCentroid(data[i]);
                
                if (assignments.get(i) != nearestCluster) {
                    assignments.set(i, nearestCluster);
                    changed = true;
                }
            }
            
            // Schritt 2: Update - Berechne neue Zentroide
            updateCentroids(data);
            
            // Konvergenz-Check
            if (!changed) {
                System.out.println("K-Means konvergiert nach " + (iteration + 1) + " Iterationen");
                break;
            }
        }
    }
    
    // Initialisiere k zuf√§llige Zentroide aus den Datenpunkten
    private double[][] initializeCentroids(double[][] data) {
        double[][] centroids = new double[k][data[0].length];
        Random random = new Random();
        Set<Integer> usedIndices = new HashSet<>();
        
        for (int i = 0; i < k; i++) {
            int index;
            do {
                index = random.nextInt(data.length);
            } while (usedIndices.contains(index));
            
            usedIndices.add(index);
            centroids[i] = Arrays.copyOf(data[index], data[index].length);
        }
        
        return centroids;
    }
    
    // K-Means++ Initialisierung (verbesserte Methode)
    private double[][] initializeCentroidsPlusPlus(double[][] data) {
        double[][] centroids = new double[k][data[0].length];
        Random random = new Random();
        
        // W√§hle ersten Zentroid zuf√§llig
        int firstIndex = random.nextInt(data.length);
        centroids[0] = Arrays.copyOf(data[firstIndex], data[firstIndex].length);
        
        // W√§hle weitere Zentroide basierend auf Distanz
        for (int i = 1; i < k; i++) {
            double[] distances = new double[data.length];
            double sumDistances = 0;
            
            // Berechne Distanz zum n√§chsten Zentroid f√ºr jeden Punkt
            for (int j = 0; j < data.length; j++) {
                double minDist = Double.MAX_VALUE;
                for (int c = 0; c < i; c++) {
                    double dist = euclideanDistance(data[j], centroids[c]);
                    minDist = Math.min(minDist, dist);
                }
                distances[j] = minDist * minDist;  // Quadrierte Distanz
                sumDistances += distances[j];
            }
            
            // W√§hle neuen Zentroid mit Wahrscheinlichkeit proportional zur Distanz
            double rand = random.nextDouble() * sumDistances;
            double cumSum = 0;
            for (int j = 0; j < data.length; j++) {
                cumSum += distances[j];
                if (cumSum >= rand) {
                    centroids[i] = Arrays.copyOf(data[j], data[j].length);
                    break;
                }
            }
        }
        
        return centroids;
    }
    
    // Findet n√§chsten Zentroid f√ºr einen Punkt
    private int findNearestCentroid(double[] point) {
        int nearest = 0;
        double minDistance = Double.MAX_VALUE;
        
        for (int i = 0; i < k; i++) {
            double distance = euclideanDistance(point, centroids[i]);
            if (distance < minDistance) {
                minDistance = distance;
                nearest = i;
            }
        }
        
        return nearest;
    }
    
    // Aktualisiert Zentroide basierend auf zugeordneten Punkten
    private void updateCentroids(double[][] data) {
        int dimensions = data[0].length;
        
        // Initialisiere neue Zentroide
        double[][] newCentroids = new double[k][dimensions];
        int[] clusterSizes = new int[k];
        
        // Summiere alle Punkte pro Cluster
        for (int i = 0; i < data.length; i++) {
            int cluster = assignments.get(i);
            clusterSizes[cluster]++;
            
            for (int d = 0; d < dimensions; d++) {
                newCentroids[cluster][d] += data[i][d];
            }
        }
        
        // Berechne Mittelwert (neue Zentroide)
        for (int i = 0; i < k; i++) {
            if (clusterSizes[i] > 0) {
                for (int d = 0; d < dimensions; d++) {
                    newCentroids[i][d] /= clusterSizes[i];
                }
                centroids[i] = newCentroids[i];
            }
            // Falls Cluster leer: behalte alten Zentroid
        }
    }
    
    // Berechnet euklidische Distanz
    private double euclideanDistance(double[] point1, double[] point2) {
        double sum = 0;
        for (int i = 0; i < point1.length; i++) {
            sum += Math.pow(point1[i] - point2[i], 2);
        }
        return Math.sqrt(sum);
    }
    
    // Berechnet Within-Cluster Sum of Squares (WCSS)
    public double calculateWCSS(double[][] data) {
        double wcss = 0;
        
        for (int i = 0; i < data.length; i++) {
            int cluster = assignments.get(i);
            wcss += Math.pow(euclideanDistance(data[i], centroids[cluster]), 2);
        }
        
        return wcss;
    }
    
    // Elbow-Methode zur optimalen k-Bestimmung
    public static void elbowMethod(double[][] data, int maxK) {
        System.out.println("Elbow-Methode f√ºr k=1 bis k=" + maxK);
        System.out.println("k\tWCSS");
        
        for (int k = 1; k <= maxK; k++) {
            KMeans kmeans = new KMeans(k, 100);
            kmeans.fit(data);
            double wcss = kmeans.calculateWCSS(data);
            System.out.println(k + "\t" + String.format("%.2f", wcss));
        }
    }
    
    // Getter-Methoden
    public double[][] getCentroids() {
        return centroids;
    }
    
    public List<Integer> getAssignments() {
        return assignments;
    }
    
    // Beispiel-Hauptmethode
    public static void main(String[] args) {
        // Erstelle Beispieldaten
        double[][] data = {
            {2, 3},
            {2, 4},
            {3, 3},
            {8, 7},
            {8, 8},
            {9, 7},
            {25, 80},
            {26, 81},
            {24, 79}
        };
        
        // F√ºhre K-Means mit k=3 aus
        KMeans kmeans = new KMeans(3, 100);
        kmeans.fit(data);
        
        // Zeige Ergebnisse
        System.out.println("\nCluster-Zuordnungen:");
        for (int i = 0; i < data.length; i++) {
            System.out.println("Punkt " + Arrays.toString(data[i]) + 
                             " -> Cluster " + kmeans.getAssignments().get(i));
        }
        
        System.out.println("\nFinal Zentroide:");
        for (int i = 0; i < kmeans.k; i++) {
            System.out.println("Cluster " + i + ": " + 
                             Arrays.toString(kmeans.getCentroids()[i]));
        }
        
        // Teste Elbow-Methode
        System.out.println("\n");
        elbowMethod(data, 5);
    }
}
    </pre>

    <!-- MinMax Implementierung -->
    <h3>Min-Max Implementierung</h3>
    
    <h4>Pseudocode Min-Max mit Alpha-Beta-Pruning</h4>
    <pre>
FUNKTION minimax(node, depth, isMaximizingPlayer, alpha, beta)
    // Basisfall: Blattknoten oder maximale Tiefe
    WENN depth = 0 ODER node ist Terminalknoten:
        RETURN evaluate(node)
    ENDE WENN
    
    WENN isMaximizingPlayer:
        maxEval = -INFINITY
        
        F√úR JEDES child IN getChildren(node):
            eval = minimax(child, depth-1, FALSE, alpha, beta)
            maxEval = max(maxEval, eval)
            alpha = max(alpha, eval)
            
            // Alpha-Beta Pruning
            WENN beta <= alpha:
                BREAK  // Beta-Cutoff
            ENDE WENN
        ENDE F√úR
        
        RETURN maxEval
    SONST:
        minEval = +INFINITY
        
        F√úR JEDES child IN getChildren(node):
            eval = minimax(child, depth-1, TRUE, alpha, beta)
            minEval = min(minEval, eval)
            beta = min(beta, eval)
            
            // Alpha-Beta Pruning
            WENN beta <= alpha:
                BREAK  // Alpha-Cutoff
            ENDE WENN
        ENDE F√úR
        
        RETURN minEval
    ENDE WENN
ENDE FUNKTION

// Hauptfunktion zum Finden des besten Zugs
FUNKTION findBestMove(currentState, depth)
    bestMove = null
    bestValue = -INFINITY
    alpha = -INFINITY
    beta = +INFINITY
    
    F√úR JEDEN move IN getPossibleMoves(currentState):
        newState = makeMove(currentState, move)
        moveValue = minimax(newState, depth-1, FALSE, alpha, beta)
        
        WENN moveValue > bestValue:
            bestValue = moveValue
            bestMove = move
        ENDE WENN
        
        alpha = max(alpha, moveValue)
    ENDE F√úR
    
    RETURN bestMove
ENDE FUNKTION
    </pre>

    <h4>Java-Implementierung Min-Max (Tic-Tac-Toe Beispiel)</h4>
    <pre>
public class MinMaxTicTacToe {
    // Spielbrett (3x3)
    private char[][] board;
    private static final char PLAYER_X = 'X';  // Maximierer
    private static final char PLAYER_O = 'O';  // Minimierer
    private static final char EMPTY = '-';
    
    // Statistiken f√ºr Alpha-Beta-Pruning
    private int nodesEvaluated = 0;
    private int pruningOccurred = 0;
    
    public MinMaxTicTacToe() {
        board = new char[3][3];
        initializeBoard();
    }
    
    // Initialisiere leeres Brett
    private void initializeBoard() {
        for (int i = 0; i < 3; i++) {
            for (int j = 0; j < 3; j++) {
                board[i][j] = EMPTY;
            }
        }
    }
    
    // Klasse f√ºr Z√ºge
    class Move {
        int row, col;
        
        public Move(int row, int col) {
            this.row = row;
            this.col = col;
        }
    }
    
    // Minimax mit Alpha-Beta-Pruning
    public int minimax(char[][] board, int depth, boolean isMaximizing, 
                       int alpha, int beta) {
        nodesEvaluated++;
        
        // Terminal-Zustand √ºberpr√ºfen
        int score = evaluate(board);
        
        // Basisfall: Gewinn/Verlust/Unentschieden oder maximale Tiefe
        if (score == 10 || score == -10) {
            return score;
        }
        if (!hasMovesLeft(board) || depth == 0) {
            return 0;  // Unentschieden
        }
        
        if (isMaximizing) {
            int maxEval = Integer.MIN_VALUE;
            
            // Durchlaufe alle m√∂glichen Z√ºge
            for (int i = 0; i < 3; i++) {
                for (int j = 0; j < 3; j++) {
                    if (board[i][j] == EMPTY) {
                        // Mache Zug
                        board[i][j] = PLAYER_X;
                        
                        // Rekursiver Aufruf
                        int eval = minimax(board, depth - 1, false, alpha, beta);
                        
                        // R√ºckg√§ngig machen
                        board[i][j] = EMPTY;
                        
                        // Update max und alpha
                        maxEval = Math.max(maxEval, eval);
                        alpha = Math.max(alpha, eval);
                        
                        // Alpha-Beta-Pruning
                        if (beta <= alpha) {
                            pruningOccurred++;
                            break;  // Beta-Cutoff
                        }
                    }
                }
            }
            return maxEval;
        } 
        else {  // Minimizing player
            int minEval = Integer.MAX_VALUE;
            
            for (int i = 0; i < 3; i++) {
                for (int j = 0; j < 3; j++) {
                    if (board[i][j] == EMPTY) {
                        // Mache Zug
                        board[i][j] = PLAYER_O;
                        
                        // Rekursiver Aufruf
                        int eval = minimax(board, depth - 1, true, alpha, beta);
                        
                        // R√ºckg√§ngig machen
                        board[i][j] = EMPTY;
                        
                        // Update min und beta
                        minEval = Math.min(minEval, eval);
                        beta = Math.min(beta, eval);
                        
                        // Alpha-Beta-Pruning
                        if (beta <= alpha) {
                            pruningOccurred++;
                            break;  // Alpha-Cutoff
                        }
                    }
                }
            }
            return minEval;
        }
    }
    
    // Evaluierungsfunktion f√ºr Tic-Tac-Toe
    private int evaluate(char[][] board) {
        // √úberpr√ºfe Zeilen
        for (int row = 0; row < 3; row++) {
            if (board[row][0] == board[row][1] && 
                board[row][1] == board[row][2]) {
                if (board[row][0] == PLAYER_X)
                    return 10;
                else if (board[row][0] == PLAYER_O)
                    return -10;
            }
        }
        
        // √úberpr√ºfe Spalten
        for (int col = 0; col < 3; col++) {
            if (board[0][col] == board[1][col] && 
                board[1][col] == board[2][col]) {
                if (board[0][col] == PLAYER_X)
                    return 10;
                else if (board[0][col] == PLAYER_O)
                    return -10;
            }
        }
        
        // √úberpr√ºfe Diagonalen
        if (board[0][0] == board[1][1] && 
            board[1][1] == board[2][2]) {
            if (board[0][0] == PLAYER_X)
                return 10;
            else if (board[0][0] == PLAYER_O)
                return -10;
        }
        
        if (board[0][2] == board[1][1] && 
            board[1][1] == board[2][0]) {
            if (board[0][2] == PLAYER_X)
                return 10;
            else if (board[0][2] == PLAYER_O)
                return -10;
        }
        
        // Kein Gewinner
        return 0;
    }
    
    // √úberpr√ºfe ob noch Z√ºge m√∂glich sind
    private boolean hasMovesLeft(char[][] board) {
        for (int i = 0; i < 3; i++) {
            for (int j = 0; j < 3; j++) {
                if (board[i][j] == EMPTY) {
                    return true;
                }
            }
        }
        return false;
    }
    
    // Finde besten Zug f√ºr Maximierer
    public Move findBestMove(char[][] board) {
        int bestVal = Integer.MIN_VALUE;
        Move bestMove = new Move(-1, -1);
        
        // Reset Statistiken
        nodesEvaluated = 0;
        pruningOccurred = 0;
        
        // Durchlaufe alle Zellen
        for (int i = 0; i < 3; i++) {
            for (int j = 0; j < 3; j++) {
                // √úberpr√ºfe ob Zelle leer ist
                if (board[i][j] == EMPTY) {
                    // Mache Zug
                    board[i][j] = PLAYER_X;
                    
                    // Berechne Wert f√ºr diesen Zug
                    int moveVal = minimax(board, 9, false, 
                                        Integer.MIN_VALUE, Integer.MAX_VALUE);
                    
                    // R√ºckg√§ngig machen
                    board[i][j] = EMPTY;
                    
                    // Update bester Zug
                    if (moveVal > bestVal) {
                        bestMove.row = i;
                        bestMove.col = j;
                        bestVal = moveVal;
                    }
                }
            }
        }
        
        System.out.println("Knoten evaluiert: " + nodesEvaluated);
        System.out.println("Pruning aufgetreten: " + pruningOccurred + " mal");
        
        return bestMove;
    }
    
    // Zeige Brett
    public void printBoard() {
        System.out.println("  0 1 2");
        for (int i = 0; i < 3; i++) {
            System.out.print(i + " ");
            for (int j = 0; j < 3; j++) {
                System.out.print(board[i][j] + " ");
            }
            System.out.println();
        }
        System.out.println();
    }
    
    // Hauptmethode zum Testen
    public static void main(String[] args) {
        MinMaxTicTacToe game = new MinMaxTicTacToe();
        
        // Setze einige Z√ºge
        game.board[0][0] = PLAYER_X;
        game.board[0][1] = PLAYER_O;
        game.board[1][1] = PLAYER_X;
        game.board[2][0] = PLAYER_O;
        
        System.out.println("Aktuelles Brett:");
        game.printBoard();
        
        // Finde besten Zug
        Move bestMove = game.findBestMove(game.board);
        
        System.out.println("Bester Zug f√ºr X: Zeile " + bestMove.row + 
                         ", Spalte " + bestMove.col);
        
        // Mache besten Zug
        game.board[bestMove.row][bestMove.col] = PLAYER_X;
        
        System.out.println("\nBrett nach bestem Zug:");
        game.printBoard();
    }
}
    </pre>

    <!-- Hilfsklassen und Utilities -->
    <h3>Hilfsklassen und Utilities</h3>
    
    <h4>Distanzberechnungen (Utility-Klasse)</h4>
    <pre>
public class DistanceUtils {
    
    // Euklidische Distanz
    public static double euclideanDistance(double[] p1, double[] p2) {
        if (p1.length != p2.length) {
            throw new IllegalArgumentException("Dimensionen m√ºssen √ºbereinstimmen");
        }
        
        double sum = 0.0;
        for (int i = 0; i < p1.length; i++) {
            sum += Math.pow(p1[i] - p2[i], 2);
        }
        return Math.sqrt(sum);
    }
    
    // Manhattan-Distanz (City-Block)
    public static double manhattanDistance(double[] p1, double[] p2) {
        if (p1.length != p2.length) {
            throw new IllegalArgumentException("Dimensionen m√ºssen √ºbereinstimmen");
        }
        
        double sum = 0.0;
        for (int i = 0; i < p1.length; i++) {
            sum += Math.abs(p1[i] - p2[i]);
        }
        return sum;
    }
    
    // Hamming-Distanz (f√ºr kategorische Daten)
    public static int hammingDistance(String[] s1, String[] s2) {
        if (s1.length != s2.length) {
            throw new IllegalArgumentException("Arrays m√ºssen gleiche L√§nge haben");
        }
        
        int distance = 0;
        for (int i = 0; i < s1.length; i++) {
            if (!s1[i].equals(s2[i])) {
                distance++;
            }
        }
        return distance;
    }
    
    // Minkowski-Distanz (generalisierte Form)
    public static double minkowskiDistance(double[] p1, double[] p2, double p) {
        if (p1.length != p2.length) {
            throw new IllegalArgumentException("Dimensionen m√ºssen √ºbereinstimmen");
        }
        
        double sum = 0.0;
        for (int i = 0; i < p1.length; i++) {
            sum += Math.pow(Math.abs(p1[i] - p2[i]), p);
        }
        return Math.pow(sum, 1.0 / p);
    }
    
    // Cosinus-√Ñhnlichkeit (f√ºr Textdokumente)
    public static double cosineSimilarity(double[] v1, double[] v2) {
        if (v1.length != v2.length) {
            throw new IllegalArgumentException("Vektoren m√ºssen gleiche L√§nge haben");
        }
        
        double dotProduct = 0.0;
        double norm1 = 0.0;
        double norm2 = 0.0;
        
        for (int i = 0; i < v1.length; i++) {
            dotProduct += v1[i] * v2[i];
            norm1 += v1[i] * v1[i];
            norm2 += v2[i] * v2[i];
        }
        
        if (norm1 == 0.0 || norm2 == 0.0) {
            return 0.0;
        }
        
        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }
}
    </pre>

    <h4>Normalisierungs-Utilities</h4>
    <pre>
public class NormalizationUtils {
    
    // Min-Max Normalisierung (auf [0,1])
    public static double[][] minMaxNormalize(double[][] data) {
        int rows = data.length;
        int cols = data[0].length;
        double[][] normalized = new double[rows][cols];
        
        for (int j = 0; j < cols; j++) {
            double min = Double.MAX_VALUE;
            double max = Double.MIN_VALUE;
            
            // Finde Min und Max f√ºr jede Spalte
            for (int i = 0; i < rows; i++) {
                min = Math.min(min, data[i][j]);
                max = Math.max(max, data[i][j]);
            }
            
            // Normalisiere
            double range = max - min;
            for (int i = 0; i < rows; i++) {
                if (range != 0) {
                    normalized[i][j] = (data[i][j] - min) / range;
                } else {
                    normalized[i][j] = 0.5;  // Wenn alle Werte gleich
                }
            }
        }
        
        return normalized;
    }
    
    // Z-Score Normalisierung (Standardisierung)
    public static double[][] zScoreNormalize(double[][] data) {
        int rows = data.length;
        int cols = data[0].length;
        double[][] normalized = new double[rows][cols];
        
        for (int j = 0; j < cols; j++) {
            // Berechne Mittelwert
            double mean = 0.0;
            for (int i = 0; i < rows; i++) {
                mean += data[i][j];
            }
            mean /= rows;
            
            // Berechne Standardabweichung
            double stdDev = 0.0;
            for (int i = 0; i < rows; i++) {
                stdDev += Math.pow(data[i][j] - mean, 2);
            }
            stdDev = Math.sqrt(stdDev / rows);
            
            // Standardisiere
            for (int i = 0; i < rows; i++) {
                if (stdDev != 0) {
                    normalized[i][j] = (data[i][j] - mean) / stdDev;
                } else {
                    normalized[i][j] = 0.0;
                }
            }
        }
        
        return normalized;
    }
    
    // Robuste Skalierung (mit Median und IQR)
    public static double[][] robustScale(double[][] data) {
        int rows = data.length;
        int cols = data[0].length;
        double[][] scaled = new double[rows][cols];
        
        for (int j = 0; j < cols; j++) {
            // Sortiere Spalte f√ºr Median und Quartile
            double[] column = new double[rows];
            for (int i = 0; i < rows; i++) {
                column[i] = data[i][j];
            }
            Arrays.sort(column);
            
            // Berechne Median (Q2)
            double median;
            if (rows % 2 == 0) {
                median = (column[rows/2 - 1] + column[rows/2]) / 2;
            } else {
                median = column[rows/2];
            }
            
            // Berechne Q1 und Q3
            double q1 = column[rows/4];
            double q3 = column[3*rows/4];
            double iqr = q3 - q1;
            
            // Skaliere
            for (int i = 0; i < rows; i++) {
                if (iqr != 0) {
                    scaled[i][j] = (data[i][j] - median) / iqr;
                } else {
                    scaled[i][j] = 0.0;
                }
            }
        }
        
        return scaled;
    }
}
    </pre>
</section>

<!-- Pr√ºfungstipps f√ºr Programmierung -->
<section id="pruefungstipps-code">
    <h2>üíª Pr√ºfungstipps f√ºr Code-Aufgaben</h2>
    
    <div class="highlight">
        <strong>Wichtig:</strong> In der Klassenarbeit musst du zeigen, dass du die Algorithmen nicht nur verstehst, sondern auch implementieren kannst!
    </div>

    <h3>Checkliste f√ºr Code-Aufgaben</h3>
    
    <div class="card card-success">
        <h4>‚úÖ Allgemeine Code-Struktur</h4>
        <ul>
            <li>Sinnvolle <strong>Variablennamen</strong> verwenden (nicht x, y, z)</li>
            <li><strong>Kommentare</strong> an wichtigen Stellen einf√ºgen</li>
            <li>Code <strong>einr√ºcken</strong> und strukturieren</li>
            <li><strong>Edge Cases</strong> beachten (leere Arrays, k > n, etc.)</li>
            <li><strong>Validierung</strong> der Eingaben durchf√ºhren</li>
        </ul>
    </div>

    <div class="card card-warning">
        <h4>‚ö†Ô∏è H√§ufige Fehler vermeiden</h4>
        <ul>
            <li><strong>Array-Grenzen:</strong> Immer auf Index-Out-of-Bounds achten</li>
            <li><strong>Null-Pointer:</strong> Auf null-Werte pr√ºfen</li>
            <li><strong>Division durch 0:</strong> Bei Normalisierung und Mittelwertberechnung</li>
            <li><strong>Unendliche Schleifen:</strong> Abbruchbedingungen definieren</li>
            <li><strong>Falsche Datentypen:</strong> int vs. double bei Berechnungen</li>
        </ul>
    </div>

    <h3>Typische Code-Aufgaben in der Pr√ºfung</h3>

    <div class="beispiel">
        <h4>Aufgabe 1: k-NN Distanzberechnung implementieren</h4>
        <p><strong>Aufgabenstellung:</strong> "Implementiere eine Methode zur Berechnung der euklidischen Distanz"</p>
        <pre>
// Musterl√∂sung:
public double euclideanDistance(double[] p1, double[] p2) {
    // Validierung
    if (p1 == null || p2 == null) {
        throw new IllegalArgumentException("Punkte d√ºrfen nicht null sein");
    }
    if (p1.length != p2.length) {
        throw new IllegalArgumentException("Punkte m√ºssen gleiche Dimension haben");
    }
    
    // Berechnung
    double sum = 0.0;
    for (int i = 0; i < p1.length; i++) {
        double diff = p1[i] - p2[i];
        sum += diff * diff;  // Effizienter als Math.pow()
    }
    
    return Math.sqrt(sum);
}
        </pre>
    </div>

    <div class="beispiel">
        <h4>Aufgabe 2: K-Means Zentroid-Update</h4>
        <p><strong>Aufgabenstellung:</strong> "Implementiere die Neuberechnung eines Zentroids"</p>
        <pre>
// Musterl√∂sung:
public double[] calculateCentroid(List<double[]> clusterPoints) {
    // Edge Case: Leerer Cluster
    if (clusterPoints == null || clusterPoints.isEmpty()) {
        return null;
    }
    
    int dimensions = clusterPoints.get(0).length;
    double[] centroid = new double[dimensions];
    
    // Summiere alle Koordinaten
    for (double[] point : clusterPoints) {
        for (int d = 0; d < dimensions; d++) {
            centroid[d] += point[d];
        }
    }
    
    // Teile durch Anzahl Punkte (Mittelwert)
    int size = clusterPoints.size();
    for (int d = 0; d < dimensions; d++) {
        centroid[d] /= size;
    }
    
    return centroid;
}
        </pre>
    </div>

    <div class="beispiel">
        <h4>Aufgabe 3: Min-Max Evaluation</h4>
        <p><strong>Aufgabenstellung:</strong> "Implementiere die Minimax-Evaluation f√ºr einen gegebenen Knoten"</p>
        <pre>
// Musterl√∂sung:
public int minimax(Node node, int depth, boolean isMaxPlayer) {
    // Basisfall: Blattknoten oder Tiefe 0
    if (depth == 0 || node.isTerminal()) {
        return node.evaluate();
    }
    
    if (isMaxPlayer) {
        int maxEval = Integer.MIN_VALUE;
        // Durchlaufe alle Kindknoten
        for (Node child : node.getChildren()) {
            int eval = minimax(child, depth - 1, false);
            maxEval = Math.max(maxEval, eval);
        }
        return maxEval;
    } else {
        int minEval = Integer.MAX_VALUE;
        // Durchlaufe alle Kindknoten
        for (Node child : node.getChildren()) {
            int eval = minimax(child, depth - 1, true);
            minEval = Math.min(minEval, eval);
        }
        return minEval;
    }
}
        </pre>
    </div>

    <h3>Quick Reference - Wichtige Java-Methoden</h3>
    <table>
        <tr>
            <th>Operation</th>
            <th>Java-Code</th>
            <th>Verwendung</th>
        </tr>
        <tr>
            <td>Quadratwurzel</td>
            <td><code>Math.sqrt(x)</code></td>
            <td>Distanzberechnung</td>
        </tr>
        <tr>
            <td>Potenz</td>
            <td><code>Math.pow(x, n)</code></td>
            <td>Quadrieren bei Distanz</td>
        </tr>
        <tr>
            <td>Absolutwert</td>
            <td><code>Math.abs(x)</code></td>
            <td>Manhattan-Distanz</td>
        </tr>
        <tr>
            <td>Maximum</td>
            <td><code>Math.max(a, b)</code></td>
            <td>Maximierer in MinMax</td>
        </tr>
        <tr>
            <td>Minimum</td>
            <td><code>Math.min(a, b)</code></td>
            <td>Minimierer in MinMax</td>
        </tr>
        <tr>
            <td>Sortieren</td>
            <td><code>Arrays.sort(array)</code></td>
            <td>k-NN Nachbarn</td>
        </tr>
        <tr>
            <td>Liste sortieren</td>
            <td><code>Collections.sort(list)</code></td>
            <td>Distanzen ordnen</td>
        </tr>
    </table>

    <div class="wichtig">
        <strong>Merke f√ºr die Pr√ºfung:</strong>
        <ul>
            <li>Schreibe <strong>sauberen, lesbaren Code</strong> - Lesbarkeit vor Cleverness!</li>
            <li>Vergiss nicht die <strong>Imports</strong> (java.util.*, java.util.List, etc.)</li>
            <li>Teste mental mit <strong>kleinen Beispielen</strong> (2-3 Datenpunkte)</li>
            <li>Bei Zeitdruck: <strong>Pseudocode</strong> ist besser als gar kein Code!</li>
        </ul>
    </div>
</section>

    <!-- Zusammenfassung Section -->
    <section id="zusammenfassung">
        <h2>Zusammenfassung und Pr√ºfungstipps</h2>

        <h3>Vergleich der Algorithmen</h3>
        <table>
            <tr>
                <th>Algorithmus</th>
                <th>Typ</th>
                <th>Lernart</th>
                <th>Hauptanwendung</th>
            </tr>
            <tr>
                <td><strong>k-NN</strong></td>
                <td>Klassifikation</td>
                <td>√úberwacht (Supervised)</td>
                <td>Vorhersage von Kategorien</td>
            </tr>
            <tr>
                <td><strong>K-Means</strong></td>
                <td>Clustering</td>
                <td>Un√ºberwacht (Unsupervised)</td>
                <td>Gruppierung √§hnlicher Daten</td>
            </tr>
            <tr>
                <td><strong>Min-Max</strong></td>
                <td>Entscheidung</td>
                <td>Spieltheorie</td>
                <td>Optimale Spielz√ºge</td>
            </tr>
        </table>

        <h3>Wichtigste Formeln</h3>
        
        <h4>k-NN: Euklidische Distanz</h4>
        <div class="formula">
d(p,q) = ‚àö[Œ£(p<sub>i</sub> - q<sub>i</sub>)¬≤]
</div>
        <h4>k-NN: Normalisierung</h4>
        <div class="formula">
x<sub>norm</sub> = (x - x<sub>min</sub>) / (x<sub>max</sub> - x<sub>min</sub>)
</div>
        <h4>K-Means: Zentroid</h4>
        <div class="formula">
Œº<sub>i</sub> = (1/n) √ó Œ£(x<sub>j</sub>)  f√ºr alle x<sub>j</sub> in Cluster C<sub>i</sub>
</div>
        <h4>Min-Max: Maximierer</h4>
        <div class="formula">
Max(s) = max[a ‚àà A(s)] Min(Result(s, a))
</div>
        <h4>Alpha-Beta: Pruning-Bedingung</h4>
        <div class="formula">
Wenn Œ± ‚â• Œ≤, dann Pruning
</div>
        <h3>Pr√ºfungstipps</h3>
        
        <div class="card card-success">
            <h4>k-NN Pr√ºfungstipps ‚úÖ</h4>
            <ul>
                <li>Immer normalisieren bei unterschiedlichen Wertebereichen</li>
                <li>Ungerade k-Werte bei bin√§rer Klassifikation w√§hlen</li>
                <li>Distanzberechnung sauber durchf√ºhren (alle Dimensionen)</li>
                <li>Mehrheitsentscheidung korrekt z√§hlen</li>
                <li>Vor- und Nachteile im Kontext erkl√§ren k√∂nnen</li>
            </ul>
        </div>

        <div class="card card-success">
            <h4>K-Means Pr√ºfungstipps ‚úÖ</h4>
            <ul>
                <li>Zentroid als Mittelwert aller Koordinaten berechnen</li>
                <li>Iterativer Prozess: Assignment ‚Üí Update ‚Üí Check</li>
                <li>Elbow-Methode zur k-Bestimmung verstehen</li>
                <li>Problem der Initialisierung kennen (k-means++)</li>
                <li>Anwendungen in eigenen Worten erkl√§ren k√∂nnen</li>
            </ul>
        </div>

        <div class="card card-success">
            <h4>Min-Max Pr√ºfungstipps ‚úÖ</h4>
            <ul>
                <li>Spielbaum von unten nach oben evaluieren</li>
                <li>Max w√§hlt Maximum, Min w√§hlt Minimum</li>
                <li>Alpha-Beta-Cutoffs erkennen und begr√ºnden k√∂nnen</li>
                <li>Komplexit√§t O(b<sup>d</sup>) kennen</li>
                <li>Annahme optimalen Spiels verstehen</li>
            </ul>
        </div>

        <h3>Typische Pr√ºfungsaufgaben</h3>

        <div class="beispiel">
            <h4>Aufgabe 1: k-NN Klassifikation</h4>
            <p><strong>Gegeben:</strong> Trainingsdaten mit Attributen und Klassen, neuer zu klassifizierender Punkt, k=3</p>
            <p><strong>Gefordert:</strong></p>
            <ol>
                <li>Normalisiere die Daten</li>
                <li>Berechne alle Distanzen</li>
                <li>Bestimme die 3 n√§chsten Nachbarn</li>
                <li>Klassifiziere durch Mehrheitsentscheidung</li>
            </ol>
        </div>

        <div class="beispiel">
            <h4>Aufgabe 2: K-Means Durchf√ºhrung</h4>
            <p><strong>Gegeben:</strong> Datenpunkte und k=2 initiale Zentroide</p>
            <p><strong>Gefordert:</strong></p>
            <ol>
                <li>Ordne jeden Punkt dem n√§chsten Zentroid zu</li>
                <li>Berechne neue Zentroide</li>
                <li>F√ºhre Iteration durch bis Konvergenz</li>
                <li>Erkl√§re, warum Algorithmus konvergiert ist</li>
            </ol>
        </div>

        <div class="beispiel">
            <h4>Aufgabe 3: Min-Max Evaluation</h4>
            <p><strong>Gegeben:</strong> Spielbaum mit Terminalwerten</p>
            <p><strong>Gefordert:</strong></p>
            <ol>
                <li>Evaluiere Baum mit Minimax-Algorithmus</li>
                <li>Bestimme optimalen Zug f√ºr Maximierer</li>
                <li>Markiere, wo Alpha-Beta-Cutoffs auftreten w√ºrden</li>
                <li>Berechne eingesparte Knoten durch Pruning</li>
            </ol>
        </div>

        <h3>Abschlussw√∂rter</h3>
        <div class="highlight">
            <p><strong>Dieser Lernzettel deckt alle relevanten KI-Themen f√ºr das Informatik-Abitur ab.</strong></p>
            <p>Wichtige Erfolgsfaktoren:</p>
            <ul>
                <li>‚úÖ Verstehe die <strong>Grundprinzipien</strong> jedes Algorithmus</li>
                <li>‚úÖ √úbe die <strong>Berechnungen</strong> an Beispielen</li>
                <li>‚úÖ Kenne <strong>Vor- und Nachteile</strong> jedes Verfahrens</li>
                <li>‚úÖ Erkenne <strong>Anwendungsf√§lle</strong> und w√§hle passenden Algorithmus</li>
                <li>‚úÖ Beherrsche die <strong>Formeln</strong> auswendig</li>
            </ul>
            <p style="text-align: center; margin-top: 1.5rem; font-size: 1.2rem;">
                <strong>Viel Erfolg bei deiner Abiturpr√ºfung! üéì</strong>
            </p>
        </div>
    </section>
</div>

<footer style="background: var(--text-primary); color: white; padding: 2rem; text-align: center; margin-top: 3rem;">
    <p>KI Lernzettel - Abitur Vorbereitung 2025</p>
    <p style="opacity: 0.8; margin-top: 0.5rem;">Basierend auf Musterpr√ºfungsaufgaben und mezmedia.de Ressourcen</p>
</footer>
</body>

</html>



