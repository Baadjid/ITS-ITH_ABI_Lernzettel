<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KI Lernzettel - Abitur Vorbereitung</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
    :root {
        --primary-color: #2563eb;
        --secondary-color: #1e40af;
        --accent-color: #3b82f6;
        --bg-color: #f8fafc;
        --card-bg: #ffffff;
        --text-primary: #1e293b;
        --text-secondary: #475569;
        --border-color: #e2e8f0;
        --success-color: #10b981;
        --warning-color: #f59e0b;
        --danger-color: #ef4444;
    }

    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        line-height: 1.7;
        color: var(--text-primary);
        background: var(--bg-color);
        padding-top: 80px;
    }

    /* Header & Navigation */
    header {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        color: white;
        padding: 1.5rem 0;
        top: 0;
        width: 100%;
        z-index: 1000;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }

    header h1 {
        text-align: center;
        font-size: 2rem;
        margin-bottom: 0.5rem;
    }

    nav {
        background: var(--card-bg);
        padding: 1rem 0;
        position: sticky;
        top: 0px;
        z-index: 999;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    nav ul {
        display: flex;
        justify-content: center;
        flex-wrap: wrap;
        list-style: none;
        max-width: 1200px;
        margin: 0 auto;
        padding: 0 2rem;
    }

    nav li {
        margin: 0.5rem;
    }

    nav a {
        color: var(--text-primary);
        text-decoration: none;
        padding: 0.5rem 1rem;
        border-radius: 6px;
        transition: all 0.3s ease;
        font-weight: 500;
    }

    nav a:hover {
        background: var(--primary-color);
        color: white;
    }

    /* Container */
    .container {
        max-width: 1200px;
        margin: 0 auto;
        padding: 2rem;
    }

    /* Sections */
    section {
        background: var(--card-bg);
        margin: 2rem 0;
        padding: 2.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
    }

    section h2 {
        color: var(--primary-color);
        font-size: 2rem;
        margin-bottom: 1.5rem;
        padding-bottom: 0.75rem;
        border-bottom: 3px solid var(--primary-color);
    }

    section h3 {
        color: var(--secondary-color);
        font-size: 1.5rem;
        margin: 2rem 0 1rem;
    }

    section h4 {
        color: var(--text-primary);
        font-size: 1.2rem;
        margin: 1.5rem 0 0.75rem;
        font-weight: 600;
    }

    /* Cards */
    .card {
        background: var(--bg-color);
        padding: 1.5rem;
        margin: 1.5rem 0;
        border-radius: 8px;
        border-left: 4px solid var(--primary-color);
    }

    .card-success {
        border-left-color: var(--success-color);
    }

    .card-warning {
        border-left-color: var(--warning-color);
    }

    .card-danger {
        border-left-color: var(--danger-color);
    }

    /* Formula Box */
    .formula {
        background: #f1f5f9;
        padding: 1.5rem;
        margin: 1rem 0;
        border-radius: 8px;
        font-family: 'Courier New', monospace;
        font-size: 1.1rem;
        overflow-x: auto;
        border: 2px solid var(--border-color);
    }

    /* Code Block */
    pre {
        background: #1e293b;
        color: #e2e8f0;
        padding: 1.5rem;
        border-radius: 8px;
        overflow-x: auto;
        margin: 1rem 0;
        font-size: 0.9rem;
        line-height: 1.6;
    }

    /* Lists */
    ul, ol {
        margin: 1rem 0 1rem 2rem;
    }

    li {
        margin: 0.5rem 0;
    }

    /* Tables */
    table {
        width: 100%;
        border-collapse: collapse;
        margin: 1.5rem 0;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    }

    th, td {
        padding: 1rem;
        text-align: left;
        border: 1px solid var(--border-color);
    }

    th {
        background: var(--primary-color);
        color: white;
        font-weight: 600;
    }

    tr:nth-child(even) {
        background: var(--bg-color);
    }

    /* Highlight Box */
    .highlight {
        background: linear-gradient(135deg, #dbeafe, #bfdbfe);
        padding: 1.5rem;
        border-radius: 8px;
        margin: 1.5rem 0;
        border-left: 4px solid var(--primary-color);
    }

    .highlight strong {
        color: var(--primary-color);
    }

    /* Important Note */
    .wichtig {
        background: #fef3c7;
        padding: 1rem 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        border-left: 4px solid var(--warning-color);
    }

    .wichtig::before {
        content: "‚ö†Ô∏è Wichtig: ";
        font-weight: bold;
        color: var(--warning-color);
    }

    /* Example Box */
    .beispiel {
        background: #d1fae5;
        padding: 1.5rem;
        border-radius: 8px;
        margin: 1.5rem 0;
        border-left: 4px solid var(--success-color);
    }

    .beispiel h4 {
        color: var(--success-color);
        margin-top: 0;
    }

    /* Two Column Layout */
    .two-column {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 2rem;
        margin: 1.5rem 0;
    }

    /* Responsive */
    @media (max-width: 768px) {
    /* Tabellen scrollbar machen */
    table {
        display: block;
        overflow-x: auto;
        -webkit-overflow-scrolling: touch;
        font-size: 0.85rem;
    }
    
    th, td {
        padding: 0.75rem 0.5rem;
        min-width: 100px;
    }
    
    /* Formeln anpassen */
    .formula {
        font-size: 0.85rem;
        padding: 1rem;
    }
    
    /* Pre/Code kleiner */
    pre {
        font-size: 0.75rem;
        padding: 1rem;
    }
    
    /* Breadcrumb anpassen */
    .breadcrumb {
        font-size: 0.85rem;
        padding: 0.75rem;
    }
    
    /* Cards mit weniger Padding */
    .card, .card-success, .card-warning, .card-danger {
        padding: 1rem;
    }
    
    .beispiel, .wichtig, .highlight {
        padding: 1rem;
    }
}

    /* Print Styles */
    @media print {
        body {
            padding-top: 0;
        }

        header, nav {
            position: static;
        }

        section {
            page-break-inside: avoid;
        }
    }

    /* Smooth Scroll */
    html {
        scroll-behavior: smooth;
    }

    /* Strong emphasis */
    strong {
        color: var(--primary-color);
        font-weight: 600;
    }

    p {
        margin: 1rem 0;
    }

        /* F√ºr sehr kleine Handys */
@media (max-width: 400px) {
    body {
        padding-top: 50px;
    }
    
    header h1 {
        font-size: 1.25rem;
    }
    
    header p {
        font-size: 0.85rem;
    }
    
    .container {
        padding: 0.5rem;
    }
    
    section {
        padding: 1rem;
        margin: 1rem 0;
    }
    
    section h2 {
        font-size: 1.3rem;
    }
    
    section h3 {
        font-size: 1.15rem;
    }
    
    nav a {
        padding: 0.4rem 0.8rem;
        font-size: 0.85rem;
    }
}
</style>
</head>
<body>
    <header>
        <h1>ü§ñ K√ºnstliche Intelligenz - Abitur Lernzettel</h1>
        <p style="text-align: center; opacity: 0.9;">Umfassende Vorbereitung f√ºr das Informatik-Abitur</p>
    </header>
<nav>
    <ul>
        <li><a href="#ueberblick">√úberblick</a></li>
        <li><a href="#knn">k-NN Verfahren</a></li>
        <li><a href="#kmeans">K-Means</a></li>
        <li><a href="#minmax">Min-Max</a></li>
        <li><a href="#zusammenfassung">Zusammenfassung</a></li>
    </ul>
</nav>
<div class="container">
    <div class="breadcrumb">
         üè† <a href="index.html">Abitur 2026 Informatik TG</a> ‚Üí 
        <a >√úberblick √ºber K√ºnstliche Intelligenz</a> 
    </div>
    <!-- √úberblick Section -->
    <section id="ueberblick">
        <h2>√úberblick √ºber K√ºnstliche Intelligenz</h2>
        
        <div class="highlight">
            <strong>K√ºnstliche Intelligenz (KI)</strong> bezeichnet Systeme, die menschen√§hnliche Intelligenzleistungen erbringen. Im Abitur werden verschiedene KI-Ans√§tze unterschieden: wissensbasierte Systeme und maschinelles Lernen. 
        </div>
        
        <div class="highlight">
            üëæ <a href="https://www.geeksforgeeks.org/machine-learning/machine-learning/">Machine Learning Source</a> 
        </div>

        <h3>Definitionen und Grundkonzepte</h3>
        <div class="two-column">
            <div class="card">
                <h4>Starke KI (Strong AI)</h4>
                <p>Systeme mit echtem Bewusstsein und Verst√§ndnis, die menschliche Intelligenz vollst√§ndig nachbilden k√∂nnen.</p>
            </div>
            <div class="card">
                <h4>Schwache KI (Weak AI)</h4>
                <p>Systeme f√ºr spezifische Aufgaben ohne echtes Verst√§ndnis. Beispiele: Sprachassistenten, Bilderkennung, Empfehlungssysteme.</p>
            </div>
        </div>

        <h3>Kategorien von KI-Ans√§tzen</h3>
        
        <h4>1. Wissensbasierte Ans√§tze</h4>
        <div class="card card-success">
            <p><strong>Definition:</strong> Systeme, bei denen Wissen explizit und nachvollziehbar gespeichert, erzeugt, genutzt oder abgefragt werden kann.</p>
            
            <p><strong>Komponenten:</strong></p>
            <ul>
                <li><strong>Suchalgorithmen</strong> (z.B. A*-Algorithmus) </li>
                <li><strong>Expertensysteme</strong> mit von Experten bereitgestellten Regeln </li>
                <li><strong>Entscheidungsbaumlernen</strong> </li>
            </ul>

            <p><strong>Vorteile:</strong></p>
            <ul>
                <li>‚úÖ Schlussfolgerungen sind nachvollziehbar (<em>Folgerichtigkeit</em>) </li>
                <li>‚úÖ Transparente Entscheidungsfindung</li>
            </ul>

            <p><strong>Nachteile:</strong></p>
            <ul>
                <li>‚ùå Nicht vollst√§ndig: Kann einfache Aufgaben wie Bild-Unterscheidung nicht l√∂sen </li>
                <li>‚ùå Wissen muss explizit formulierbar sein</li>
            </ul>
        </div>

        <h4>2. Maschinelles Lernen</h4>
        <div class="card card-success">
            <p><strong>Definition:</strong> Ein System wird f√ºr seine Aufgabe "trainiert" anstatt explizit programmiert. </p>
            
            <p><strong>Ans√§tze:</strong></p>
            <ul>
                <li><strong>√úberwachtes Lernen</strong> (Supervised Learning): Training mit gelabelten Daten</li>
                <li><strong>Un√ºberwachtes Lernen</strong> (Unsupervised Learning): Muster in ungelabelten Daten finden</li>
                <li><strong>Verst√§rkendes Lernen</strong> (Reinforcement Learning): Lernen durch Belohnung/Bestrafung</li>
            </ul>
        </div>

        <h3>Turing-Test</h3>
        <p>Der nach Alan Turing benannte Test stellt die Frage: <em>"Wie k√∂nnen wir feststellen, ob eine Maschine intelligent ist?"</em></p>
        <p>Ein Mensch kommuniziert mit einer Maschine und einem anderen Menschen, ohne zu wissen, wer wer ist. Kann der Mensch nicht unterscheiden, welcher Gespr√§chspartner die Maschine ist, gilt der Test als bestanden.</p>

        <h3>Wichtige Begriffe f√ºr das Abitur</h3>
        <table>
            <tr>
                <th>Begriff</th>
                <th>Erkl√§rung</th>
            </tr>
            <tr>
                <td><strong>Gelabelte Daten</strong></td>
                <td>Daten, die bereits einer Klasse zugeordnet wurden </td>
            </tr>
            <tr>
                <td><strong>Trainingsdaten</strong></td>
                <td>Gelabelte Daten zum "Trainieren" des Algorithmus </td>
            </tr>
            <tr>
                <td><strong>Testdaten</strong></td>
                <td>Gelabelte Daten zur Evaluation der Algorithmusqualit√§t </td>
            </tr>
            <tr>
                <td><strong>Overfitting</strong></td>
                <td>√úberanpassung an Trainingsdaten, schlechte Generalisierung</td>
            </tr>
            <tr>
                <td><strong>Underfitting</strong></td>
                <td>Zu einfaches Modell, erfasst Muster nicht ausreichend</td>
            </tr>
        </table>
    </section>

    <!-- k-NN Section -->
    <section id="knn">
        <h2>k-N√§chste-Nachbarn-Verfahren (k-NN)</h2>

        <div class="highlight">
            <strong>k-Nearest Neighbor (k-NN)</strong> ist ein instanzenbasiertes Klassifikationsverfahren. Die Klassifikation erfolgt durch Mehrheitsentscheidung der k √§hnlichsten Trainingsbeispiele. 
        </div>

        <h3>Grundprinzip</h3>
        <p>Bei der Klassifizierung neuer Datens√§tze werden die <strong>√§hnlichsten Beispieldatens√§tze gesucht</strong> (die Nachbarn). Die Klasse, die bei diesen Nachbarn am h√§ufigsten auftritt, wird der neuen Instanz zugeordnet.</p>

        <div class="card">
            <p><strong>Charakteristika:</strong></p>
            <ul>
                <li>üîπ <strong>Lazy Learning</strong>: Kein eigentliches Training, nur Abspeichern der Beispiele </li>
                <li>üîπ <strong>Instanzenbasiert</strong>: Trainingsdaten selbst repr√§sentieren das Wissen </li>
                <li>üîπ <strong>Nichtparametrisch</strong>: Keine Annahmen √ºber Datenverteilung </li>
                <li>üîπ Funktioniert f√ºr quantitative UND qualitative Merkmale </li>
            </ul>
        </div>

        <h3>Algorithmus-Schritte</h3>
        <div class="card card-success">
            <ol>
                <li><strong>Pr√ºfung auf gleiche Dimension</strong> aller Punkte </li>
                <li><strong>Sicherstellung eines g√ºltigen k-Werts</strong> (k ‚â§ Anzahl Trainingspunkte) </li>
                <li><strong>Berechnung der Distanzen</strong> zu allen Trainingspunkten </li>
                <li><strong>Sortierung der Distanzen</strong> (aufsteigend)</li>
                <li><strong>Auswahl der k kleinsten Distanzen</strong></li>
                <li><strong>Mehrheitsentscheidung</strong>: H√§ufigste Klasse unter den k Nachbarn gewinnt </li>
                <li><strong>R√ºckgabe</strong> der vorhergesagten Klasse</li>
            </ol>
        </div>

        <h3>Distanzma√üe</h3>
        
        <h4>1. Euklidische Distanz (am h√§ufigsten verwendet)</h4>
        <div class="formula">
dist<sub>E</sub>(v,w) = ‚àö(Œ£(v<sub>i</sub> - w<sub>i</sub>)¬≤)
</div>
<p>Die Summe der quadrierten Differenzen aller Attributwerte. Entspricht der "Luftlinie" zwischen zwei Punkten. ibm</p>
        <h4>2. Manhattan-Distanz</h4>
        <div class="formula">
dist<sub>M</sub>(v,w) = Œ£|v<sub>i</sub> - w<sub>i</sub>|
</div>
<p>Die Summe der absoluten Differenzen. Entspricht dem Weg entlang von Stra√üen in einer Stadt. ibm</p>
        <h4>3. Hamming-Distanz (f√ºr kategorische Daten)</h4>
        <div class="formula">
dist<sub>H</sub>(v,w) = count(v<sub>i</sub> ‚â† w<sub>i</sub>)
</div>
<p>Anzahl der Attributwerte, bei denen v und w unterschiedlich sind. Gitlab</p>
        <h3>Normalisierung</h3>
        <div class="wichtig">
            Bei stark unterschiedlichen Wertebereichen ist eine <strong>Normalisierung erforderlich</strong>, um Ungleichgewichtung zu vermeiden!
        </div>

        <div class="formula">
x<sub>normalisiert</sub> = (x - x<sub>min</sub>) / (x<sub>max</sub> - x<sub>min</sub>)
</div>
        <div class="beispiel">
            <h4>Beispiel: Warum Normalisierung wichtig ist</h4>
            <p>Gegeben: Datensatz mit Attributen Alter (20-60) und Eigenheim (0-1)</p>
            <p>Ohne Normalisierung: Das Alter dominiert die Distanzberechnung komplett!</p>
            <ul>
                <li>Distanz im Alter zwischen 26 und 59: 33</li>
                <li>Distanz beim Eigenheim: maximal 1</li>
            </ul>
            <p><strong>L√∂sung:</strong> Normalisierung aller Attribute ins Intervall [0,1]</p>
        </div>

        <h3>Wahl von k</h3>
        <table>
            <tr>
                <th>k-Wert</th>
                <th>Eigenschaften</th>
                <th>Probleme</th>
            </tr>
            <tr>
                <td><strong>k = 1</strong></td>
                <td>Nur der n√§chste Nachbar z√§hlt </td>
                <td>‚ùå Sehr sensitiv gegen√ºber Ausrei√üern und Rauschen<br>‚ùå Gefahr von Overfitting</td>
            </tr>
            <tr>
                <td><strong>k klein (2-5)</strong></td>
                <td>Wenige Nachbarn beeinflussen Entscheidung</td>
                <td>‚ö†Ô∏è Noch anf√§llig f√ºr Rauschen</td>
            </tr>
            <tr>
                <td><strong>k optimal (‚àön)</strong></td>
                <td>Faustregel: k = ‚àö(Anzahl Trainingsdaten)</td>
                <td>‚úÖ Guter Kompromiss</td>
            </tr>
            <tr>
                <td><strong>k gro√ü</strong></td>
                <td>Viele Nachbarn beeinflussen</td>
                <td>‚ùå Punkte mit gro√üem Abstand beeinflussen Entscheidung<br>‚ùå Wird langsam<br>‚ùå Gefahr von Underfitting </td>
            </tr>
        </table>

        <div class="wichtig">
            Bei zwei Klassen: <strong>k ungerade w√§hlen</strong>, um Unentschieden zu vermeiden! 
        </div>

        <h3>Vorteile und Nachteile</h3>
        <div class="two-column">
            <div class="card card-success">
                <h4>Vorteile ‚úÖ</h4>
                <ul>
                    <li>Sehr einfach zu verstehen und implementieren </li>
                    <li>Keine Trainingsphase erforderlich</li>
                    <li>Funktioniert f√ºr quantitative und qualitative Merkmale </li>
                    <li>Liefert oft gute Ergebnisse </li>
                    <li>Flexibel einsetzbar</li>
                </ul>
            </div>
            <div class="card card-danger">
                <h4>Nachteile ‚ùå</h4>
                <ul>
                    <li>Aufw√§ndige Klassifikationsphase </li>
                    <li>Hoher Speicher- und Rechenaufwand bei vielen Trainingsdaten </li>
                    <li>"Curse of Dimensionality" bei hochdimensionalen R√§umen</li>
                    <li>Liefert kein explizites Wissen √ºber Klassen </li>
                    <li>Sensitiv gegen√ºber Ausrei√üern</li>
                </ul>
            </div>
        </div>

        <h3>Beispielaufgabe</h3>
        <div class="beispiel">
            <h4>Klassifikation durchf√ºhren</h4>
            <p><strong>Gegeben:</strong> 8 Trainingspunkte mit Attributen Alter, Familienstand, Ausbildung, Eigenheim und Einkommensniveau (hoch/niedrig). </p>
            <p><strong>Aufgabe:</strong> Klassifiziere einen 26-j√§hrigen, verheirateten Akademiker ohne Eigenheim mit k=2. </p>
            
            <p><strong>L√∂sungsschritte:</strong></p>
            <ol>
                <li>Normalisiere das Attribut Alter: Alter<sub>norm</sub> = (26 - 20) / (60 - 20) = 0.15</li>
                <li>Berechne Distanzen zu allen 8 Trainingspunkten (mit normalisierten Werten)</li>
                <li>Sortiere Distanzen aufsteigend</li>
                <li>W√§hle die 2 Datens√§tze mit kleinster Distanz</li>
                <li>Z√§hle Klassen: z.B. 2x "hoch" ‚Üí Vorhersage: "hohes Einkommen"</li>
            </ol>
        </div>

        <h3>Pr√ºfungsrelevante Begriffe</h3>
        <ul>
            <li><strong>Instanzenbasiertes Lernen</strong> (instance-based learning)</li>
            <li><strong>Lazy Learning</strong> (tr√§ges Lernen)</li>
            <li><strong>Merkmalsvektor</strong> (feature vector)</li>
            <li><strong>Mehrheitsentscheidung</strong> (majority vote)</li>
            <li><strong>Abstandsma√üe</strong> (distance metrics)</li>
            <li><strong>Normalisierung</strong> (normalization)</li>
        </ul>
    </section>

    <!-- K-Means Section -->
    <section id="kmeans">
        <h2>K-Means Clusteranalyse</h2>

        <div class="highlight">
            <strong>K-Means</strong> ist ein un√ºberwachtes Lernverfahren zur Clusteranalyse. Es teilt Daten in k Cluster ein, sodass Punkte innerhalb eines Clusters m√∂glichst √§hnlich und Cluster untereinander m√∂glichst verschieden sind. 
        </div>

        <h3>Grundkonzept</h3>
        <p>K-Means ist ein <strong>un√ºberwachtes Lernverfahren</strong> ‚Äì die Trainingsdaten haben keine vordefinierten Labels. Das Ziel ist es, k Clusterzentren (Zentroide) zu finden, um die Daten optimal in k Cluster aufzuteilen.</p>

        <div class="card">
            <p><strong>Charakteristika:</strong></p>
            <ul>
                <li>üîπ <strong>Un√ºberwachtes Lernen</strong>: Keine vordefinierten Klassen </li>
                <li>üîπ Jeder Datenpunkt geh√∂rt zu genau einem Cluster </li>
                <li>üîπ Cluster werden durch <strong>Zentroide</strong> (Schwerpunkte) repr√§sentiert</li>
                <li>üîπ Iterativer Optimierungsprozess</li>
            </ul>
        </div>

        <h3>Algorithmus-Schritte</h3>
        <div class="card card-success">
            <h4>Schritt 1: Initialisierung</h4>
            <ul>
                <li>W√§hle die Anzahl der Cluster <strong>k</strong> </li>
                <li>Platziere k Zentroide zuf√§llig im Datenraum (oder verwende k-means++ Methode) </li>
            </ul>

            <h4>Schritt 2: Zuordnung (Assignment)</h4>
            <ul>
                <li>F√ºr jeden Datenpunkt: Berechne Distanz zu allen k Zentroiden </li>
                <li>Ordne Punkt dem n√§chstgelegenen Zentroid zu </li>
                <li>Gib dem Punkt das Label des Zentroids </li>
            </ul>

            <h4>Schritt 3: Update (Neuberechnung)</h4>
            <ul>
                <li>F√ºr jeden Cluster: Berechne neuen Zentroid als Schwerpunkt aller Punkte im Cluster</li>
                <li>Neuer Zentroid = Mittelwert aller Punktkoordinaten im Cluster</li>
            </ul>

            <h4>Schritt 4: Konvergenzpr√ºfung</h4>
            <ul>
                <li>Haben sich die Zentroide (signifikant) bewegt?</li>
                <li><strong>NEIN</strong> ‚Üí STOP, Algorithmus konvergiert</li>
                <li><strong>JA</strong> ‚Üí Zur√ºck zu Schritt 2</li>
            </ul>
        </div>

        <h3>Formeln und Berechnungen</h3>

        <h4>Zentroid-Berechnung</h4>
        <div class="formula">
Zentroid Œº<sub>i</sub> = (1/n) √ó Œ£(x<sub>j</sub>)
wobei n = Anzahl Punkte im Cluster C<sub>i</sub>
x<sub>j</sub> = einzelne Datenpunkte
</div>
        <div class="beispiel">
            <h4>Beispiel: Zentroid berechnen</h4>
            <p>Gegeben: 3 Punkte im Cluster: (2,3), (4,5), (6,7)</p>
            <p><strong>Berechnung:</strong></p>
            <ul>
                <li>x-Koordinate: (2+4+6)/3 = 4</li>
                <li>y-Koordinate: (3+5+7)/3 = 5</li>
            </ul>
            <p><strong>Neuer Zentroid: (4, 5)</strong></p>
        </div>

        <h4>Euklidische Distanz</h4>
        <div class="formula">
d(p,q) = ‚àö[(p‚ÇÅ-q‚ÇÅ)¬≤ + (p‚ÇÇ-q‚ÇÇ)¬≤ + ... + (p‚Çô-q‚Çô)¬≤]
= ‚àö[Œ£(p·µ¢ - q·µ¢)¬≤]
</div>
        <h4>Zielfunktion (Within-Cluster Sum of Squares - WCSS)</h4>
        <div class="formula">
J = Œ£(i=1 bis k) Œ£(x<sub>j</sub> ‚àà C<sub>i</sub>) ||x<sub>j</sub> - Œº<sub>i</sub>||¬≤
Ziel: J minimieren (Summe der quadrierten Abst√§nde innerhalb der Cluster)
</div>
        <h3>Konvergenzkriterien</h3>
        <table>
            <tr>
                <th>Kriterium</th>
                <th>Beschreibung</th>
            </tr>
            <tr>
                <td><strong>Keine Neuzuordnung</strong></td>
                <td>Cluster-Zuordnungen √§ndern sich nicht mehr (h√§ufigstes Kriterium)</td>
            </tr>
            <tr>
                <td><strong>Zentroid-Stabilit√§t</strong></td>
                <td>Zentroide bewegen sich nicht mehr (√Ñnderung \u003c Schwellenwert Œµ)</td>
            </tr>
            <tr>
                <td><strong>Maximale Iterationen</strong></td>
                <td>Vordefinierte Anzahl Durchl√§ufe erreicht (z.B. 10 Iterationen)</td>
            </tr>
            <tr>
                <td><strong>Minimale Verbesserung</strong></td>
                <td>Abnahme der Zielfunktion J unter Schwellenwert</td>
            </tr>
        </table>

        <h3>Optimale Clusterzahl k bestimmen</h3>

        <h4>Elbow-Methode</h4>
        <div class="card">
            <ol>
                <li>F√ºhre K-Means f√ºr verschiedene k-Werte aus (z.B. k=1 bis 10)</li>
                <li>Berechne WCSS (Inertia) f√ºr jeden k-Wert</li>
                <li>Plotte k gegen WCSS</li>
                <li>Suche den "Ellbogen"-Punkt: Stelle, wo WCSS-Abnahme sich stark verlangsamt</li>
                <li>Dieses k ist optimal</li>
            </ol>
        </div>

        <h4>Silhouetten-Koeffizient</h4>
        <div class="formula">
Silhouette = (b - a) / max(a, b)
a = durchschnittliche Distanz zu Punkten im eigenen Cluster
b = durchschnittliche Distanz zum n√§chsten Cluster
Wertebereich: -1 bis +1
+1: Punkt liegt gut im eigenen Cluster
0: Punkt liegt an Clustergrenze
-1: Punkt ist falsch zugeordnet
</div>
        <h3>Anwendungen</h3>
        <ul>
            <li><strong>Kundensegmentierung</strong>: Gruppierung von Kunden mit √§hnlichem Kaufverhalten</li>
            <li><strong>Bildkompression</strong>: Reduktion der Farbanzahl durch Clustering im RGB-Raum</li>
            <li><strong>Dokumenten-Clustering</strong>: Gruppierung √§hnlicher Dokumente oder Texte</li>
            <li><strong>Anomalieerkennung</strong>: Identifikation von Ausrei√üern (Spam, Betrug)</li>
            <li><strong>Marktforschung</strong>: Marktsegmentierung f√ºr gezielte Kampagnen</li>
            <li><strong>Qualit√§tskontrolle</strong>: Produktklassifizierung nach Qualit√§tsstufen</li>
        </ul>

        <div class="beispiel">
            <h4>Beispiel: Bildkompression</h4>
            <p><strong>Originalbild:</strong> 16,7 Millionen Farben (RGB: 256¬≥)</p>
            <p><strong>Nach K-Means mit k=15:</strong> Nur noch 15 Farben</p>
            <p><strong>Ergebnis:</strong> 60% Speicherreduktion, Kerninhalt bleibt erkennbar</p>
            <p><strong>Methode:</strong> Jeder Pixel = Datenpunkt (R,G,B). K-Means findet 15 repr√§sentative Farben.</p>
        </div>

        <h3>Vorteile und Nachteile</h3>
        <div class="two-column">
            <div class="card card-success">
                <h4>Vorteile ‚úÖ</h4>
                <ul>
                    <li>Sehr schnell und effizient</li>
                    <li>Skalierbar f√ºr gro√üe Datenmengen</li>
                    <li>Einfach zu verstehen und implementieren</li>
                    <li>Funktioniert gut bei sph√§rischen Clustern</li>
                    <li>Geringe Speicher- und Rechenanforderungen</li>
                </ul>
            </div>
            <div class="card card-danger">
                <h4>Nachteile ‚ùå</h4>
                <ul>
                    <li>k muss vorher festgelegt werden</li>
                    <li>Ergebnis h√§ngt von Initialisierung ab</li>
                    <li>Sensitiv gegen√ºber Ausrei√üern</li>
                    <li>Funktioniert nur f√ºr sph√§rische Cluster</li>
                    <li>Nur numerische Daten (kategorische m√ºssen encodiert werden)</li>
                    <li>Keine Garantie f√ºr globales Optimum</li>
                </ul>
            </div>
        </div>

        <h3>Wichtige Hinweise f√ºr die Pr√ºfung</h3>
        <div class="wichtig">
            <strong>Datenaufbereitung ist essentiell:</strong>
            <ul>
                <li>Alle Features normalisieren/standardisieren</li>
                <li>Ausrei√üer vorher entfernen</li>
                <li>Kategorische Variablen m√ºssen encodiert werden</li>
                <li>Keine fehlenden Werte erlaubt</li>
            </ul>
        </div>

        <div class="wichtig">
            <strong>Initialisierung verbessern:</strong>
            <ul>
                <li>Verwende k-means++ statt zuf√§lliger Initialisierung</li>
                <li>F√ºhre Algorithmus mehrmals aus (verschiedene Starts)</li>
                <li>W√§hle Ergebnis mit niedrigster Inertia</li>
            </ul>
        </div>
    </section>

    <!-- MinMax Section -->
    <section id="minmax">
        <h2>Min-Max-Algorithmus</h2>

        <div class="highlight">
            <strong>Minimax</strong> ist ein rekursiver Entscheidungsalgorithmus f√ºr 2-Personen-Nullsummenspiele. Er minimiert den maximalen Verlust und maximiert den minimalen Gewinn unter der Annahme optimalen Spiels beider Spieler.
        </div>

        <h3>Grundkonzept</h3>
        <p>Der Minimax-Algorithmus wird in der Spieltheorie und bei Computerspielen eingesetzt. Er ist besonders relevant f√ºr:</p>
        <ul>
            <li>Rundenbasierte Spiele (Schach, Dame, Tic-Tac-Toe)</li>
            <li>Spiele mit <strong>vollst√§ndiger Information</strong> (keine versteckten Karten)</li>
            <li><strong>Nullsummenspiele</strong>: Gewinn des einen = Verlust des anderen</li>
        </ul>

        <h3>Die zwei Spieler</h3>
        <div class="two-column">
            <div class="card card-success">
                <h4>Maximierer (Max)</h4>
                <ul>
                    <li>M√∂chte den Score <strong>maximieren</strong></li>
                    <li>W√§hlt Zug mit h√∂chstem Nutzen</li>
                    <li>Repr√§sentiert die KI oder den Spieler</li>
                    <li>Nimmt an, Gegner spielt optimal</li>
                </ul>
            </div>
            <div class="card card-danger">
                <h4>Minimierer (Min)</h4>
                <ul>
                    <li>M√∂chte den Score des Maximierers <strong>minimieren</strong></li>
                    <li>W√§hlt Zug mit niedrigstem Nutzen f√ºr Max</li>
                    <li>Repr√§sentiert den Gegner</li>
                    <li>Nimmt ebenfalls optimales Spiel an</li>
                </ul>
            </div>
        </div>

        <h3>Spielbaum-Struktur</h3>
        <div class="card">
            <p><strong>Komponenten eines Spielbaums:</strong></p>
            <ul>
                <li><strong>Wurzelknoten (Root)</strong>: Aktueller Spielzustand</li>
                <li><strong>Innere Knoten</strong>: Zwischenzust√§nde des Spiels</li>
                <li><strong>Blattknoten (Terminal Nodes)</strong>: Endzust√§nde (Gewinn/Verlust/Unentschieden)</li>
                <li><strong>Kanten</strong>: M√∂gliche Z√ºge/Aktionen</li>
                <li><strong>Tiefe (Depth)</strong>: Anzahl Z√ºge vorausschauend (gemessen in "Plies")</li>
                <li><strong>Verzweigungsfaktor (Branching Factor)</strong>: Durchschnittliche Anzahl legaler Z√ºge</li>
            </ul>
        </div>

        <h3>Algorithmus-Schritte</h3>
        <div class="card card-success">
            <h4>Schritt 1: Spielbaum generieren</h4>
            <p>Erstelle Baumstruktur aller m√∂glichen Z√ºge vom aktuellen Spielzustand aus.</p>

            <h4>Schritt 2: Terminale Zust√§nde bewerten</h4>
            <p>Weise Nutzenwerte den Blattknoten zu:</p>
            <ul>
                <li>+1 (oder +‚àû): Maximierer gewinnt</li>
                <li>0: Unentschieden</li>
                <li>-1 (oder -‚àû): Minimierer gewinnt</li>
            </ul>

            <h4>Schritt 3: Werte nach oben propagieren (Backtracking)</h4>
            <p>F√ºr jeden inneren Knoten:</p>
            <ul>
                <li><strong>Max-Knoten</strong>: W√§hle MAXIMUM der Kindknoten</li>
                <li><strong>Min-Knoten</strong>: W√§hle MINIMUM der Kindknoten</li>
            </ul>

            <h4>Schritt 4: Optimalen Zug w√§hlen</h4>
            <p>Am Wurzelknoten: Maximierer w√§hlt den Zug mit dem h√∂chsten Wert.</p>
        </div>

        <h3>Mathematische Formeln</h3>

        <h4>F√ºr Maximierer</h4>
        <div class="formula">
Max(s) = max[a ‚àà A(s)] Min(Result(s, a))
s = aktueller Zustand
A(s) = Menge aller m√∂glichen Aktionen
Result(s, a) = Resultatszustand nach Aktion a
</div>
        <h4>F√ºr Minimierer</h4>
        <div class="formula">
Min(s) = min[a ‚àà A(s)] Max(Result(s, a))
</div>
        <h4>Nutzenfunktion f√ºr terminale Zust√§nde</h4>
        <div class="formula">
Utility(s) = {
+1  wenn Maximierer gewinnt
0  bei Unentschieden
-1  wenn Minimierer gewinnt
}
</div>
        <h3>Beispiel: Minimax-Baum evaluieren</h3>
        <div class="beispiel">
            <h4>Beispiel mit Terminalwerten [3, 5, 2, 9]</h4>
            <pre>
            Maximierer (Root)
           /                \
     Minimierer            Minimierer
     /      \             /      \
    3       5           2        9
            </pre>

            <p><strong>Evaluation:</strong></p>
            <ol>
                <li><strong>Minimierer LINKS:</strong> min(3, 5) = 3</li>
                <li><strong>Minimierer RECHTS:</strong> min(2, 9) = 2</li>
                <li><strong>Maximierer:</strong> max(3, 2) = 3</li>
            </ol>
            <p><strong>Optimaler Wert: 3 (Maximierer geht nach LINKS)</strong></p>
            <p><em>Hinweis:</em> Obwohl der Wert 9 existiert, wird der Minimierer ihn nie w√§hlen!</p>
        </div>

        <h3>Alpha-Beta-Pruning (Optimierung)</h3>
        <p>Alpha-Beta-Pruning ist eine Optimierungstechnik, die Zweige abschneidet, die das Endergebnis nicht beeinflussen k√∂nnen.</p>

        <h4>Parameter</h4>
        <div class="two-column">
            <div class="card">
                <h4>Alpha (Œ±)</h4>
                <p>Bester Wert f√ºr den Maximierer bisher gefunden</p>
                <p>Initialisierung: Œ± = -‚àû</p>
                <p>Wird beim Maximierer aktualisiert</p>
            </div>
            <div class="card">
                <h4>Beta (Œ≤)</h4>
                <p>Bester Wert f√ºr den Minimierer bisher gefunden</p>
                <p>Initialisierung: Œ≤ = +‚àû</p>
                <p>Wird beim Minimierer aktualisiert</p>
            </div>
        </div>

        <h4>Pruning-Bedingung</h4>
        <div class="formula">
Wenn Œ± ‚â• Œ≤, dann schneide verbleibende Zweige ab (Pruning)
</div>
        <h4>Funktionsweise</h4>
        <div class="card card-warning">
            <p><strong>Bei Maximierer-Knoten:</strong></p>
            <ul>
                <li>Aktualisiere Œ± mit bestem gefundenen Wert</li>
                <li>Wenn Œ± ‚â• Œ≤: <strong>PRUNE</strong> (Minimierer wird diesen Pfad nie w√§hlen)</li>
            </ul>

            <p><strong>Bei Minimierer-Knoten:</strong></p>
            <ul>
                <li>Aktualisiere Œ≤ mit bestem gefundenen Wert</li>
                <li>Wenn Œ≤ ‚â§ Œ±: <strong>PRUNE</strong> (Maximierer wird diesen Pfad nie zulassen)</li>
            </ul>
        </div>

        <h4>Vorteile von Alpha-Beta-Pruning</h4>
        <ul>
            <li>‚úÖ <strong>Effizienz:</strong> Reduziert Anzahl zu evaluierender Knoten erheblich</li>
            <li>‚úÖ Erm√∂glicht tiefere Suche mit gleichen Ressourcen</li>
            <li>‚úÖ <strong>Optimale Entscheidungen:</strong> Garantiert gleiches Ergebnis wie Minimax</li>
            <li>‚úÖ Kann Millionen Positionen einsparen</li>
        </ul>

        <h3>Pseudocode</h3>
        <pre>
function minimax(state, depth, maximizingPlayer):
if depth = 0 or state is terminal:
return utility(state)
if maximizingPlayer:
    maxEval = -‚àû
    for action in actions(state):
        eval = minimax(result(state, action), depth-1, False)
        maxEval = max(maxEval, eval)
    return maxEval
else:
    minEval = +‚àû
    for action in actions(state):
        eval = minimax(result(state, action), depth-1, True)
        minEval = min(minEval, eval)
    return minEval
        </pre>

        <h3>Komplexit√§t</h3>
        <table>
            <tr>
                <th>Variante</th>
                <th>Zeitkomplexit√§t</th>
                <th>Beschreibung</th>
            </tr>
            <tr>
                <td><strong>Minimax ohne Pruning</strong></td>
                <td>O(b<sup>d</sup>)</td>
                <td>b = Verzweigungsfaktor, d = Tiefe</td>
            </tr>
            <tr>
                <td><strong>Alpha-Beta (optimal)</strong></td>
                <td>O(b<sup>d/2</sup>)</td>
                <td>Verdoppelt effektiv die Suchtiefe</td>
            </tr>
            <tr>
                <td><strong>Raumkomplexit√§t</strong></td>
                <td>O(bd)</td>
                <td>Analog zu Tiefensuche (DFS)</td>
            </tr>
        </table>

        <h3>Anwendungen</h3>
        <ul>
            <li><strong>Schach:</strong> IBM Deep Blue besiegte 1997 Weltmeister Garry Kasparov</li>
            <li><strong>Dame (Checkers):</strong> Chinook gewann 1994 Weltmeisterschaft</li>
            <li><strong>Tic-Tac-Toe:</strong> Perfektes Spiel f√ºhrt immer zu Unentschieden</li>
            <li><strong>Othello/Reversi:</strong> Effektiv mit Evaluationsfunktionen</li>
            <li><strong>AlphaZero (DeepMind):</strong> Kombination von Minimax mit Deep Learning</li>
        </ul>

        <h3>Vorteile und Nachteile</h3>
        <div class="two-column">
            <div class="card card-success">
                <h4>Vorteile ‚úÖ</h4>
                <ul>
                    <li>Garantiert optimale Entscheidung</li>
                    <li>Einfach zu verstehen</li>
                    <li>Deterministisch</li>
                    <li>Vollst√§ndig (findet L√∂sung wenn vorhanden)</li>
                    <li>Gut f√ºr Spiele mit perfekter Information</li>
                </ul>
            </div>
            <div class="card card-danger">
                <h4>Nachteile ‚ùå</h4>
                <ul>
                    <li><strong>Exponenzielle Komplexit√§t O(b<sup>d</sup>)</strong></li>
                    <li>Unpraktisch f√ºr Spiele mit tiefem/komplexem Baum</li>
                    <li>Tiefenbegrenzung notwendig ‚Üí suboptimale Entscheidungen</li>
                    <li>Nimmt deterministische Ergebnisse an</li>
                    <li>Effektivit√§t h√§ngt von Zugreihenfolge ab (Alpha-Beta)</li>
                    <li>Kein Lernen aus Erfahrung</li>
                </ul>
            </div>
        </div>

        <h3>Wichtig f√ºr die Pr√ºfung</h3>
        <div class="wichtig">
            <ul>
                <li>Minimax-Baum Schritt f√ºr Schritt evaluieren k√∂nnen</li>
                <li>Verstehen, wann Alpha-Beta-Cutoffs auftreten</li>
                <li>Unterschied zwischen Maximierer und Minimierer erkl√§ren k√∂nnen</li>
                <li>Komplexit√§tsanalyse kennen (O(b<sup>d</sup>) vs. O(b<sup>d/2</sup>))</li>
                <li>Annahme optimalen Spiels beider Spieler verstehen</li>
                <li>Anwendungsbeispiele kennen (Deep Blue, Schach, Dame)</li>
            </ul>
        </div>
    </section>

    <!-- Zusammenfassung Section -->
    <section id="zusammenfassung">
        <h2>Zusammenfassung und Pr√ºfungstipps</h2>

        <h3>Vergleich der Algorithmen</h3>
        <table>
            <tr>
                <th>Algorithmus</th>
                <th>Typ</th>
                <th>Lernart</th>
                <th>Hauptanwendung</th>
            </tr>
            <tr>
                <td><strong>k-NN</strong></td>
                <td>Klassifikation</td>
                <td>√úberwacht (Supervised)</td>
                <td>Vorhersage von Kategorien</td>
            </tr>
            <tr>
                <td><strong>K-Means</strong></td>
                <td>Clustering</td>
                <td>Un√ºberwacht (Unsupervised)</td>
                <td>Gruppierung √§hnlicher Daten</td>
            </tr>
            <tr>
                <td><strong>Min-Max</strong></td>
                <td>Entscheidung</td>
                <td>Spieltheorie</td>
                <td>Optimale Spielz√ºge</td>
            </tr>
        </table>

        <h3>Wichtigste Formeln</h3>
        
        <h4>k-NN: Euklidische Distanz</h4>
        <div class="formula">
d(p,q) = ‚àö[Œ£(p<sub>i</sub> - q<sub>i</sub>)¬≤]
</div>
        <h4>k-NN: Normalisierung</h4>
        <div class="formula">
x<sub>norm</sub> = (x - x<sub>min</sub>) / (x<sub>max</sub> - x<sub>min</sub>)
</div>
        <h4>K-Means: Zentroid</h4>
        <div class="formula">
Œº<sub>i</sub> = (1/n) √ó Œ£(x<sub>j</sub>)  f√ºr alle x<sub>j</sub> in Cluster C<sub>i</sub>
</div>
        <h4>Min-Max: Maximierer</h4>
        <div class="formula">
Max(s) = max[a ‚àà A(s)] Min(Result(s, a))
</div>
        <h4>Alpha-Beta: Pruning-Bedingung</h4>
        <div class="formula">
Wenn Œ± ‚â• Œ≤, dann Pruning
</div>
        <h3>Pr√ºfungstipps</h3>
        
        <div class="card card-success">
            <h4>k-NN Pr√ºfungstipps ‚úÖ</h4>
            <ul>
                <li>Immer normalisieren bei unterschiedlichen Wertebereichen</li>
                <li>Ungerade k-Werte bei bin√§rer Klassifikation w√§hlen</li>
                <li>Distanzberechnung sauber durchf√ºhren (alle Dimensionen)</li>
                <li>Mehrheitsentscheidung korrekt z√§hlen</li>
                <li>Vor- und Nachteile im Kontext erkl√§ren k√∂nnen</li>
            </ul>
        </div>

        <div class="card card-success">
            <h4>K-Means Pr√ºfungstipps ‚úÖ</h4>
            <ul>
                <li>Zentroid als Mittelwert aller Koordinaten berechnen</li>
                <li>Iterativer Prozess: Assignment ‚Üí Update ‚Üí Check</li>
                <li>Elbow-Methode zur k-Bestimmung verstehen</li>
                <li>Problem der Initialisierung kennen (k-means++)</li>
                <li>Anwendungen in eigenen Worten erkl√§ren k√∂nnen</li>
            </ul>
        </div>

        <div class="card card-success">
            <h4>Min-Max Pr√ºfungstipps ‚úÖ</h4>
            <ul>
                <li>Spielbaum von unten nach oben evaluieren</li>
                <li>Max w√§hlt Maximum, Min w√§hlt Minimum</li>
                <li>Alpha-Beta-Cutoffs erkennen und begr√ºnden k√∂nnen</li>
                <li>Komplexit√§t O(b<sup>d</sup>) kennen</li>
                <li>Annahme optimalen Spiels verstehen</li>
            </ul>
        </div>

        <h3>Typische Pr√ºfungsaufgaben</h3>

        <div class="beispiel">
            <h4>Aufgabe 1: k-NN Klassifikation</h4>
            <p><strong>Gegeben:</strong> Trainingsdaten mit Attributen und Klassen, neuer zu klassifizierender Punkt, k=3</p>
            <p><strong>Gefordert:</strong></p>
            <ol>
                <li>Normalisiere die Daten</li>
                <li>Berechne alle Distanzen</li>
                <li>Bestimme die 3 n√§chsten Nachbarn</li>
                <li>Klassifiziere durch Mehrheitsentscheidung</li>
            </ol>
        </div>

        <div class="beispiel">
            <h4>Aufgabe 2: K-Means Durchf√ºhrung</h4>
            <p><strong>Gegeben:</strong> Datenpunkte und k=2 initiale Zentroide</p>
            <p><strong>Gefordert:</strong></p>
            <ol>
                <li>Ordne jeden Punkt dem n√§chsten Zentroid zu</li>
                <li>Berechne neue Zentroide</li>
                <li>F√ºhre Iteration durch bis Konvergenz</li>
                <li>Erkl√§re, warum Algorithmus konvergiert ist</li>
            </ol>
        </div>

        <div class="beispiel">
            <h4>Aufgabe 3: Min-Max Evaluation</h4>
            <p><strong>Gegeben:</strong> Spielbaum mit Terminalwerten</p>
            <p><strong>Gefordert:</strong></p>
            <ol>
                <li>Evaluiere Baum mit Minimax-Algorithmus</li>
                <li>Bestimme optimalen Zug f√ºr Maximierer</li>
                <li>Markiere, wo Alpha-Beta-Cutoffs auftreten w√ºrden</li>
                <li>Berechne eingesparte Knoten durch Pruning</li>
            </ol>
        </div>

        <h3>Abschlussw√∂rter</h3>
        <div class="highlight">
            <p><strong>Dieser Lernzettel deckt alle relevanten KI-Themen f√ºr das Informatik-Abitur ab.</strong></p>
            <p>Wichtige Erfolgsfaktoren:</p>
            <ul>
                <li>‚úÖ Verstehe die <strong>Grundprinzipien</strong> jedes Algorithmus</li>
                <li>‚úÖ √úbe die <strong>Berechnungen</strong> an Beispielen</li>
                <li>‚úÖ Kenne <strong>Vor- und Nachteile</strong> jedes Verfahrens</li>
                <li>‚úÖ Erkenne <strong>Anwendungsf√§lle</strong> und w√§hle passenden Algorithmus</li>
                <li>‚úÖ Beherrsche die <strong>Formeln</strong> auswendig</li>
            </ul>
            <p style="text-align: center; margin-top: 1.5rem; font-size: 1.2rem;">
                <strong>Viel Erfolg bei deiner Abiturpr√ºfung! üéì</strong>
            </p>
        </div>
    </section>
</div>

<footer style="background: var(--text-primary); color: white; padding: 2rem; text-align: center; margin-top: 3rem;">
    <p>KI Lernzettel - Abitur Vorbereitung 2025</p>
    <p style="opacity: 0.8; margin-top: 0.5rem;">Basierend auf Musterpr√ºfungsaufgaben und mezmedia.de Ressourcen</p>
</footer>
</body>

</html>

